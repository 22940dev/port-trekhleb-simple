{"componentChunkName":"component---src-templates-post-tsx","path":"/blog/2018/homemade-machine-learning-in-python/","result":{"data":{"markdownRemark":{"id":"1172e8e9-bdfe-5477-8a6f-c4691c69afa2","timeToRead":5,"html":"<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.60000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACDklEQVQoz11SWW7cMAz1/Y/SC/QrKIouH22DBkGmk2TSJmM73uTRalG7VdqeQZEShiRTfOTjE4v5YinFnLNfbZoUfqszSSnHkbUdEUJ6H8CYtBreFrj1wwDG13Vrra3rmjHmQzpRjjCt9TD0VlWKvYCejNEn0uHKOQ8hFK9NI/goxwcQR8xGOdaUanwE8YJEjLGcM6Ne7dQgDy1K1tw4wzgXIfhCCNys022wNDkp2keniJ36YMjSRQgGNNBXRcqFazTol5x0fa/1VOTNMG3OjjfPP97jOq+ufLlrfn1q919mhGrSl9eTaCnlXdddwPkcvmmBR61AMpVi2mRb8+PJAygAfRZs86JU+I96WuuW0DnfXd9/vfpmtN20zWteK357ecDjpA32u4ARSRmj9f3x5sqIHgvHiFpG53xES3O0qt1/FvUdBjsYjHiywLSGBQwAZBwFqYY/txg3r1y8xxdReUZ6GdGyPRhaxWiDGayqlaQYVmyDoZTyIcYZuc1YFJsrbz/sPr6Lhi+V1/nBNMCe4LQP3vQDcc4WF6VyCkC7By06PCPn4KwzekmUc/RyOh1yVFwsYzOOIxY7C4YscVFi7KqdEdXEq+gnUCMjZU7a6SGa1spjCmppYd6oLZB/T4XDhFKBIs3zdy07RY+ndjc72pc/rerym5c/25t3xgkSUlIqGBdpPocCOFR8Rf4P/gvQXSUkVNUXDgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Homemade Machine Learning in Python\"\n        title=\"Homemade Machine Learning in Python\"\n        src=\"/static/6a4daeb4f4a615338ca192f7993816ae/00d43/01-cover.png\"\n        srcset=\"/static/6a4daeb4f4a615338ca192f7993816ae/63868/01-cover.png 250w,\n/static/6a4daeb4f4a615338ca192f7993816ae/0b533/01-cover.png 500w,\n/static/6a4daeb4f4a615338ca192f7993816ae/00d43/01-cover.png 1000w,\n/static/6a4daeb4f4a615338ca192f7993816ae/78415/01-cover.png 1207w\"\n        sizes=\"(max-width: 1000px) 100vw, 1000px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<center><i>\nThe source of the following machine learning topics map is <a href=\"https://vas3k.ru/blog/machine_learning/\">this wonderful blog post</a>.\n</i></center>\n<p>I‚Äôve recently launched <a href=\"https://github.com/trekhleb/homemade-machine-learning\">Homemade Machine Learning</a> repository that contains examples of popular machine learning algorithms and approaches (like <em>linear/logistic regressions, K-Means clustering, neural networks</em>) implemented in <strong>Python</strong> with mathematics behind them being explained. Each algorithm has interactive <strong>Jupyter Notebook</strong> demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions <strong>right in your browser</strong>. In most cases the explanations are based on <a href=\"https://www.coursera.org/learn/machine-learning\">this great machine learning course</a> by <a href=\"https://medium.com/@andrewng\">Andrew Ng</a>.</p>\n<p>The purpose of the repository was <em>not</em> to implement machine learning algorithms by using 3rd party library ‚Äúone-liners‚Äù <em>but</em> rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. That‚Äôs why all algorithms implementations are called ‚Äúhomemade‚Äù.</p>\n<p>The main Python libraries that are used there are <a href=\"http://www.numpy.org/\">NumPy</a> and <a href=\"https://pandas.pydata.org/\">Pandas</a>. These two are used for efficient matrix operations and for loading/parsing CSV datasets. When it comes to <a href=\"http://jupyter.org/\">Jupyter Notebook</a> demos then such libraries as <a href=\"https://matplotlib.org/\">Matplotlib</a> and <a href=\"https://plot.ly/\">Plotly</a> are being used for data visualizations.</p>\n<p>Currently, the following topics have been covered:</p>\n<h2 id=\"regression-linear-regression\" style=\"position:relative;\">Regression: Linear Regression<a href=\"#regression-linear-regression\" aria-label=\"regression linear regression permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>In regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.</p>\n<p><em>Usage examples: stock price forecast, sales analysis, dependency of any number, etc.</em></p>\n<ul>\n<li>üìó <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression\">Linear Regression Math</a>  ‚Äî  theory and links for further readings</li>\n<li>‚öôÔ∏è <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression/linear_regression.py\">Linear Regression Implementation Example</a></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb\">Demo | Univariate Linear Regression</a>  ‚Äî  predict <code class=\"language-text\">country happiness</code> score by <code class=\"language-text\">economy GDP</code></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb\">Demo | Multivariate Linear Regression</a>  ‚Äî  predict <code class=\"language-text\">country happiness</code> score by <code class=\"language-text\">economy GDP</code> and <code class=\"language-text\">freedom index</code></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb\">Demo | Non-linear Regression</a>  ‚Äî  use linear regression with <em>polynomial</em> and <em>sinusoid</em> features to predict non-linear dependencies.</li>\n</ul>\n<h2 id=\"classification-logistic-regression\" style=\"position:relative;\">Classification: Logistic Regression<a href=\"#classification-logistic-regression\" aria-label=\"classification logistic regression permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>In classification problems we split input examples by certain characteristic.</p>\n<p><em>Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc.</em></p>\n<ul>\n<li>üìó <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression\">Logistic Regression Math</a>  ‚Äî  theory and links for further readings</li>\n<li>‚öôÔ∏è <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression/logistic_regression.py\">Logistic Regression Implementation Example</a></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb\">Demo | Logistic Regression (Linear Boundary)</a>  ‚Äî  predict Iris flower <code class=\"language-text\">class</code> based on <code class=\"language-text\">petal_length</code> and <code class=\"language-text\">petal_width</code></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb\">Demo | Logistic Regression (Non-Linear Boundary)</a>  ‚Äî  predict microchip <code class=\"language-text\">validity</code> based on <code class=\"language-text\">param_1</code> and <code class=\"language-text\">param_2</code></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb\">Demo | Multivariate Logistic Regression</a>  ‚Äî  recognize handwritten digits from <code class=\"language-text\">28x28</code> pixel images.</li>\n</ul>\n<h2 id=\"clustering-k-means-algorithm\" style=\"position:relative;\">Clustering: K-means Algorithm<a href=\"#clustering-k-means-algorithm\" aria-label=\"clustering k means algorithm permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>In clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.</p>\n<p><em>Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc.</em></p>\n<ul>\n<li>üìó <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means\">K-means Algorithm Math</a>  ‚Äî  theory and links for further readings</li>\n<li>‚öôÔ∏è <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means/k_means.py\">K-means Algorithm Implementation Example</a></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb\">Demo | K-means Algorithm</a>  ‚Äî  split Iris flowers into clusters based on <code class=\"language-text\">petal_length</code> and <code class=\"language-text\">petal_width</code></li>\n</ul>\n<h2 id=\"neural-networks-multilayer-perceptron-mlp\" style=\"position:relative;\">Neural Networks: Multilayer Perceptron (MLP)<a href=\"#neural-networks-multilayer-perceptron-mlp\" aria-label=\"neural networks multilayer perceptron mlp permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>The neural network itself isn‚Äôt an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.</p>\n<p><em>Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc.</em></p>\n<ul>\n<li>üìó <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network\">Multilayer Perceptron Math</a>  ‚Äî  theory and links for further readings</li>\n<li>‚öôÔ∏è <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network/multilayer_perceptron.py\">Multilayer Perceptron Implementation Example</a></li>\n<li>‚ñ∂Ô∏è <a href=\"https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb\">Demo | Multilayer Perceptron</a>  ‚Äî  recognize handwritten digits from <code class=\"language-text\">28x28</code> pixel images.</li>\n</ul>\n<h2 id=\"anomaly-detection-gaussian-distribution\" style=\"position:relative;\">Anomaly Detection: Gaussian Distribution<a href=\"#anomaly-detection-gaussian-distribution\" aria-label=\"anomaly detection gaussian distribution permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>Anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.</p>\n<p><em>Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc.</em></p>\n<ul>\n<li>üìó <a href=\"https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/anomaly_detection\">The Math Behind Anomaly Detection using Gaussian Distribution</a></li>\n</ul>\n<blockquote>\n<p>I hope you‚Äôll find <a href=\"https://github.com/trekhleb/homemade-machine-learning\">the repository</a> useful. Either by playing with demos or by reading the math sections or by simply exploring the source code. Happy coding!</p>\n</blockquote>","excerpt":"I‚Äôve recently launched Homemade Machine Learning repository that contains examples of popular machine learning algorithms and approaches (like linear/logistic regressions, K-Means clustering, neural networks) implemented in Python with mathematics behind them being explained. Each algorithm has‚Ä¶","fields":{"slug":"/blog/2018/homemade-machine-learning-in-python/"},"frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","date":"21 December, 2018","cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACDklEQVQoz11SWW7cMAz1/Y/SC/QrKIouH22DBkGmk2TSJmM73uTRalG7VdqeQZEShiRTfOTjE4v5YinFnLNfbZoUfqszSSnHkbUdEUJ6H8CYtBreFrj1wwDG13Vrra3rmjHmQzpRjjCt9TD0VlWKvYCejNEn0uHKOQ8hFK9NI/goxwcQR8xGOdaUanwE8YJEjLGcM6Ne7dQgDy1K1tw4wzgXIfhCCNys022wNDkp2keniJ36YMjSRQgGNNBXRcqFazTol5x0fa/1VOTNMG3OjjfPP97jOq+ufLlrfn1q919mhGrSl9eTaCnlXdddwPkcvmmBR61AMpVi2mRb8+PJAygAfRZs86JU+I96WuuW0DnfXd9/vfpmtN20zWteK357ecDjpA32u4ARSRmj9f3x5sqIHgvHiFpG53xES3O0qt1/FvUdBjsYjHiywLSGBQwAZBwFqYY/txg3r1y8xxdReUZ6GdGyPRhaxWiDGayqlaQYVmyDoZTyIcYZuc1YFJsrbz/sPr6Lhi+V1/nBNMCe4LQP3vQDcc4WF6VyCkC7By06PCPn4KwzekmUc/RyOh1yVFwsYzOOIxY7C4YscVFi7KqdEdXEq+gnUCMjZU7a6SGa1spjCmppYd6oLZB/T4XDhFKBIs3zdy07RY+ndjc72pc/rerym5c/25t3xgkSUlIqGBdpPocCOFR8Rf4P/gvQXSUkVNUXDgAAAABJRU5ErkJggg==","aspectRatio":1.4367816091954022,"src":"/static/6a4daeb4f4a615338ca192f7993816ae/eb0de/01-cover.png","srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/bd3a8/01-cover.png 250w,\n/static/6a4daeb4f4a615338ca192f7993816ae/0757b/01-cover.png 500w,\n/static/6a4daeb4f4a615338ca192f7993816ae/eb0de/01-cover.png 1000w,\n/static/6a4daeb4f4a615338ca192f7993816ae/3c4ef/01-cover.png 1207w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}}}},"pageContext":{"slug":"/blog/2018/homemade-machine-learning-in-python/"}},"staticQueryHashes":[]}