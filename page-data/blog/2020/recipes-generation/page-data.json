{"componentChunkName":"component---src-templates-post-tsx","path":"/blog/2020/recipes-generation/","result":{"data":{"mdx":{"id":"359b4218-4f63-572b-a1a2-60e6617ff9c4","timeToRead":13,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Generating cooking recipes using TensorFlow and LSTM Recurrent Neural Network: A step-by-step guide\",\n  \"summary\": \"I've trained a character-level LSTM RNN on ~100k recipes dataset using TensorFlow, and it suggested me to cook Cream Soda with Onions, Puff Pastry Strawberry Soup, Zucchini flavor Tea and Salmon Mousse of Beef and Stilton Salad with Jalapenos\",\n  \"cover\": \"assets/01-cover.jpeg\",\n  \"date\": \"2020-06-18T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", {\n    \"id\": \"tldr\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"TL;DR\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#tldr\",\n    \"aria-label\": \"tldr permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"I've trained a character-level LSTM \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"(Long short-term memory)\"), \" RNN \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"(Recurrent Neural Network)\"), \" on \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"~100k\"), \" recipes dataset using TensorFlow, and it suggested me to cook \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\\"Cream Soda with Onions\\\"\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\\"Puff Pastry Strawberry Soup\\\"\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\\"Zucchini flavor Tea\\\"\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\\"Salmon Mousse of Beef and Stilton Salad with Jalapenos\\\"\"), \" .\"), mdx(\"p\", null, \"Here you may find more examples of what I ended up with:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83C\\uDFA8 \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://trekhleb.dev/machine-learning-experiments/#/experiments/RecipeGenerationRNN\"\n  }, \"Cooking recipes generator demo\"), \" - to try the model interactively right in your browser.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83C\\uDFCB\\uD83C\\uDFFB\\u200D \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/trekhleb/machine-learning-experiments/blob/master/experiments/recipe_generation_rnn/recipe_generation_rnn.ipynb\"\n  }, \"LSTM model training process\"), \" - to see how the model was trained.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/trekhleb/machine-learning-experiments\"\n  }, \"\\uD83E\\uDD16 Interactive Machine Learning Experiments\"), \" repository - to see more experiments with \\\"Objects detection\\\", \\\"Sketch Recognition\\\", \\\"Image Classification\\\" etc.\")), mdx(\"p\", null, \"This article contains details of how the LSTM model was actually trained on Python using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/\"\n  }, \"TensorFlow 2\"), \" with \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/guide/keras\"\n  }, \"Keras API\"), \".\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/posts-assets/4cdea1757c71da83958f357939b859e2/02-demo.gif\",\n    \"alt\": \"Cooking recipes generator demo\"\n  })), mdx(\"h2\", {\n    \"id\": \"what-our-model-will-eventually-learn\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"What our model will eventually learn\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#what-our-model-will-eventually-learn\",\n    \"aria-label\": \"what our model will eventually learn permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"For a couple of hours of training our character-level RNN model will learn basic concepts of English grammar and punctuation (I wish I could learn English that fast!). It will also learn how to generate different parts of recipes such as \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\uD83D\\uDCD7 \", \"[RECIPE NAME]\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\uD83E\\uDD55 \", \"[RECIPE INGREDIENTS]\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\uD83D\\uDCDD \", \"[RECIPE INSTRUCTIONS]\"), \". Sometimes recipe name, ingredients and instructions will be pretty interesting, sometimes stupid, sometimes fun.\"), mdx(\"p\", null, \"Here is a couple of generated recipes examples:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7 [NAME]\\n\\nOrange Club Tea Sandwich Cookies\\n\\n\\uD83E\\uDD55 [INGREDIENTS]\\n\\n\\u2022 1 cup (2 sticks) unsalted butter, softened\\n\\u2022 1 cup confectioners' sugar\\n\\u2022 1/2 cup flaxseed meal\\n\\u2022 1/2 cup shelled pumpkin seeds (pecans, blanched and sliced)\\n\\u2022 2 teaspoons vanilla extract\\n\\n\\uD83D\\uDCDD [INSTRUCTIONS]\\n\\n\\u25AA\\uFE0E Preheat oven to 350 degrees F.\\n\\u25AA\\uFE0E Combine cake mix, milk, egg and sugar in a large bowl. Stir until combined and smooth but not sticky. Using a spatula, sprinkle the dough biscuits over the bottom of the pan. Sprinkle with sugar, and spread evenly. Bake for 20 minutes. Remove from the oven and cool on a rack. To serve, add the chocolate.\"))), mdx(\"p\", null, \"Or another one:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7 [NAME]\\n\\nMushrooms with Lentil Stewed Shallots and Tomatoes\\n\\n\\uD83E\\uDD55 [INGREDIENTS]\\n\\n\\u2022 1 tablespoon olive oil\\n\\u2022 3 cloves garlic, smashed\\n\\u2022 Kosher salt\\n\\u2022 1 1/2 pounds lean ground turkey\\n\\u2022 1 cup coarsely peeled tart apples\\n\\u2022 2 tablespoons chopped garlic\\n\\u2022 1 teaspoon ground cumin\\n\\u2022 1/2 teaspoon cayenne pepper\\n\\u2022 1 teaspoon chopped fresh thyme\\n\\u2022 3/4 cup chopped fresh basil\\n\\u2022 1/2 small carrot, halved lengthwise and cut into 1/2-inch pieces\\n\\u2022 1 roasted red pepper, halved and sliced vertically diced and separated into rough chops\\n\\u2022 3 tablespoons unsalted butter\\n\\u2022 2 cups shredded mozzarella\\n\\u2022 1/4 cup grated parmesan cheese\\n\\u2022 1/4 cup prepared basil pesto\\n\\n\\uD83D\\uDCDD [INSTRUCTIONS]\\n\\n\\u25AA\\uFE0E Stir the olive oil, garlic, thyme and 1 teaspoon salt in a saucepan; bring to a simmer over medium heat. Remove from the heat. Add the basil and toast the soup for 2 minutes.\\n\\u25AA\\uFE0E Meanwhile, heat 4 to 4 inches vegetable oil in the skillet over medium-high heat. Add the olive oil, garlic, 1/2 teaspoon salt and 1/2 teaspoon pepper and cook, stirring often, until cooked through, a\"))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"946px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"100%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMCAf/EABYBAQEBAAAAAAAAAAAAAAAAAAEDAP/aAAwDAQACEAMQAAABrlaVossduOwJv//EABoQAQEAAwEBAAAAAAAAAAAAAAECABIhMkH/2gAIAQEAAQUCjgQKUzj11NfRHM1Jz7//xAAVEQEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAwEBPwEp/8QAFhEBAQEAAAAAAAAAAAAAAAAAEAIx/9oACAECAQE/AScP/8QAHxAAAgECBwAAAAAAAAAAAAAAABEBAhIQISIxMkFR/9oACAEBAAY/AlJya6JFTU0VW6Z9Im02MsP/xAAcEAEAAgMBAQEAAAAAAAAAAAABABEhMUFhUXH/2gAIAQEAAT8hv9TdktQAKYQHvWVCxAp24HgIWhg3C1KOwP7yOcMr32O0/9oADAMBAAIAAwAAABDzPwL/xAAXEQADAQAAAAAAAAAAAAAAAAABEBEx/9oACAEDAQE/EKJVtf/EABgRAQADAQAAAAAAAAAAAAAAAAEAEBEx/9oACAECAQE/EExyYlD2f//EABwQAQEAAgMBAQAAAAAAAAAAAAERACExUWFBcf/aAAgBAQABPxBtIEzYvd3hFCENUe57kUu2zg8wBSIn6J2R4yvubIPfMMUKB3b7kNkmovL5gJ3Qqn0XrCQhBnBn/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Cook real recipes, not with generated ones\",\n    \"title\": \"Cook real recipes, not with generated ones\",\n    \"src\": \"/static/bd0d3256b5e96aafe4d1ee2392dd3b59/56d85/09.jpg\",\n    \"srcSet\": [\"/static/bd0d3256b5e96aafe4d1ee2392dd3b59/0479a/09.jpg 250w\", \"/static/bd0d3256b5e96aafe4d1ee2392dd3b59/41099/09.jpg 500w\", \"/static/bd0d3256b5e96aafe4d1ee2392dd3b59/56d85/09.jpg 946w\"],\n    \"sizes\": \"(max-width: 946px) 100vw, 946px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"\\u26A0\\uFE0F The recipes in this article are generated just for fun and for learning purposes. The recipes are \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"not\"), \" for actual cooking! If you want some real recipes you may check \\uD83E\\uDD66 \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.instagram.com/home_full_of_recipes/\"\n  }, \"home_full_of_recipes\"), \" Instagram channel.\"), mdx(\"h2\", {\n    \"id\": \"prior-knowledge\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Prior knowledge\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#prior-knowledge\",\n    \"aria-label\": \"prior knowledge permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"It is assumed that you're already familiar with concepts of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Recurrent_neural_network\"\n  }, \"Recurrent Neural Networks (RNNs)\"), \" and with \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Long_short-term_memory\"\n  }, \"Long short-term memory (LSTM)\"), \" architecture in particular.\"), mdx(\"p\", null, \"\\u2139\\uFE0F In case if these concepts are new to you I would highly recommend taking a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.coursera.org/specializations/deep-learning\"\n  }, \"Deep Learning Specialization\"), \" on Coursera by \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Andrew Ng\"), \". It also might be beneficial to go through the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\"\n  }, \"Unreasonable Effectiveness of Recurrent Neural Networks\"), \" article by \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Andrej Karpathy\"), \".\"), mdx(\"p\", null, \"On a high level, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Recurrent Neural Network (RNN)\"), \" is a class of deep neural networks, most commonly applied to sequence-based data like speech, voice, text or music. They are used for machine translation, speech recognition, voice synthesis etc. The key feature of RNNs is that they are stateful, and they have an internal memory in which some context for the sequence may be stored. For example if the first word of the sequence was \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"He\"), \" the RNN might suggest the next word to \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"speaks\"), \" instead of just \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"speak\"), \" (to form a \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"He speaks\"), \" phrase) because the prior knowledge about the first word \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"He\"), \" is already inside the internal memory.\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/posts-assets/79e174934c03239fc046bf55357ce7bd/0.svg\",\n    \"alt\": \"Recurrent Neural Network\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Image source: \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://en.wikipedia.org/wiki/Recurrent_neural_network\"\n  }, \"Wikipedia\")))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"63.6%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAACNUlEQVQoz21SWU/bQBD2v81L+Qs8tlQqILVVaUk5SkohkSERIhC5XEUxuYghJmlKDSlSQHEO3157fexuN3ECSO1Iu/vN8e3OzgxDJgIAuG21wjAk/xOMMd1lWVZV9VFlhqeiY3mAXYhCRKhR1YmikZF7QiVI1XG3H7owROjRzCCMe7oiD3qqC7QAKhD0DEXWB8GzICqe60LbwsN7cEgwGgLCqJq6eLL39mhnqZaf3d1Yapx9OuffFQ5/392S0dtBELD18iLPJa+rCwc7cZ77XDz4UOCanTZjQOdb6YjNZdaz29ObqWz56M3u8ewZ3zEHo3wJwij563x6cylR/bGQ25rPsa/20vOlwz+WwmjIT1VOuMRKhk29PBWy28mFbHKuevjgGFFhKJ+VLmd2NtJry5l0cv90b6Yovq/XHlyd0Rz74+n+WqP0ReS/1vPrUjXT/rks8jfyw2NV2Wth7ntm9TIfrxyv1PjVRiHRumwDnaE+C4DQ86BhID/wAYCWhfDzWhPTcTRg29BV+32137Mc2w58WnZm7LcBHqhYN4miUkCCEP/b6yAcdVEnnj9uFV3IcRH0xqMSEA+Np8K27WhmPM8zTXPS8icZpR1PWIuJyPU6198S9KHRBrFYTBRFijmOm3oxRUEYhDeSZBrGE7kr1jsXtUi/uOnedc3otUqlEg3j/f29IAhRgKIorutOyBjrAJiuE+k+BCgYfkmSpHw+f3V1RXGz2SwWixBCyiyXyzQdxxnG/wXQxr2rG5xSUwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Basic architectures of GRU and LSTM cells\",\n    \"title\": \"Basic architectures of GRU and LSTM cells\",\n    \"src\": \"/static/11ecf20ea5599f22b8bf1c392290aefe/00d43/1.png\",\n    \"srcSet\": [\"/static/11ecf20ea5599f22b8bf1c392290aefe/63868/1.png 250w\", \"/static/11ecf20ea5599f22b8bf1c392290aefe/0b533/1.png 500w\", \"/static/11ecf20ea5599f22b8bf1c392290aefe/00d43/1.png 1000w\", \"/static/11ecf20ea5599f22b8bf1c392290aefe/2cefc/1.png 1400w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Image source: \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\"\n  }, \"Towards Data Science\")))), mdx(\"p\", null, \"Exciting part is that RNN (and LSTM in particular) could memorize not only \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"word-to-word\"), \" dependencies but also \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"character-to-character\"), \" dependencies! It doesn't really matter what sequence consists of: it might be words it might be characters. What is important is that they form a time-distributed sequence. For example, we have a sequence of characters \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"['H', 'e']\"), \". If we ask LSTM what may go next it may suggest a \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"<stop_word>\"), \" (meaning, that the sequence that forms word \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"He\"), \" is already complete, and we may stop), or it may also suggest a character \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"l\"), \" (meaning, that it tries to build a \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"Hello\"), \" sequence for us). This type of RNNs are called \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"character-level RNNs\"), \" (as opposed to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"word-level RNNs\"), \").\"), mdx(\"p\", null, \"In this tutorial we will rely on this memorization feature of RNN networks, and we will use a character-level version of LSTM to generate cooking recipes.\"), mdx(\"h2\", {\n    \"id\": \"exploring-the-datasets\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Exploring the datasets\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#exploring-the-datasets\",\n    \"aria-label\": \"exploring the datasets permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's go through several available datasets and explore their pros and cons. One of the requirements I want the dataset to meet is that it should have not only a list of ingredients but also a cooking instruction. I also want it to have a measures and quantities for each ingredient.\"), mdx(\"p\", null, \"Here are several cooking recipes datasets I've found:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83E\\uDD37 \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home\"\n  }, \"Recipe Ingredients Dataset\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(doesn't have ingredients proportions)\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83E\\uDD37 \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://pic2recipe.csail.mit.edu/\"\n  }, \"Recipe1M+\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(a lot of recipes but requires registration to download)\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83E\\uDD37 \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kaggle.com/hugodarwood/epirecipes?select=full_format_recipes.json\"\n  }, \"Epicurious - Recipes with Rating and Nutrition\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(~20k recipes only, it would be nice to find more)\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\uD83D\\uDC4D\\uD83C\\uDFFB \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://eightportions.com/datasets/Recipes/\"\n  }, \"Recipe box\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(~125,000 recipes with ingredients proportions, good)\"))), mdx(\"p\", null, \"Let's try to use the \\\"Recipe box\\\" dataset. The number of recipes looks big enough, also it contains both ingredients and cooking instructions. It is interesting to see if RNN will be able to learn a connection between ingredients and instructions.\"), mdx(\"h2\", {\n    \"id\": \"setting-tensorflowpython-sandbox-for-training\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Setting TensorFlow/Python sandbox for training\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#setting-tensorflowpython-sandbox-for-training\",\n    \"aria-label\": \"setting tensorflowpython sandbox for training permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"There are several options you may follow to experiment with the code in this tutorial:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"You may experiment by using \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/recipe_generation_rnn/recipe_generation_rnn.ipynb\"\n  }, \"GoogleColab right in your browser\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(no local setup is needed)\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"You may experiment by using \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://mybinder.org/v2/gh/trekhleb/machine-learning-experiments/master?filepath=experiments/recipe_generation_rnn/recipe_generation_rnn.ipynb\"\n  }, \"Jupyter notebook in Binder right in your browser\"), \" \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"(no local setup is needed)\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"You may \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/trekhleb/machine-learning-experiments#how-to-use-this-repository-locally\"\n  }, \"setup a Jupyter notebook locally\"), \".\")), mdx(\"p\", null, \"I would suggest going with GoogleColab option since it doesn't require any local setup for you (you may experiment right in your browser), and it also provides a powerful GPU support for training that will make the model to train faster. You will be able to experiment with training parameters as well.\"), mdx(\"h2\", {\n    \"id\": \"importing-dependencies\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Importing dependencies\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#importing-dependencies\",\n    \"aria-label\": \"importing dependencies permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's start with importing some packages that we will use afterwards.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Packages for training the model and working with the dataset.\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" tensorflow \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" tf\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" matplotlib\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"pyplot \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" plt\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" numpy \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" np\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" json\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Utility/helper packages.\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" platform\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" time\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" pathlib\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" os\"))), mdx(\"p\", null, \"First, let's make sure our environment is properly set up and that we're using a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"2nd\"), \" version of Tensorflow.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Python version:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" platform\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"python_version\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Tensorflow version:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"__version__\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Keras version:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"__version__\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Python version: 3.7.6\\nTensorflow version: 2.1.0\\nKeras version: 2.2.4-tf\")))), mdx(\"h2\", {\n    \"id\": \"loading-the-dataset\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Loading the dataset\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#loading-the-dataset\",\n    \"aria-label\": \"loading the dataset permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's load the dataset using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\"\n  }, \"tf.keras.utils.get_file\"), \". Using \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"get_file()\"), \" utility is convenient because it handles caching for you out of the box. It means that you will download the dataset files only once and then even if you launch the same code block in the notebook once again it will use cache, and the code block will be executed faster.\"), mdx(\"p\", null, \"Create cache folder if it not exists:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"CACHE_DIR \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'./tmp'\"), \"\\npathlib\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Path\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"CACHE_DIR\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"mkdir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"exist_ok\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"Download and unpack the dataset:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset_file_name \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'recipes_raw.zip'\"), \"\\ndataset_file_origin \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'https://storage.googleapis.com/recipe-box/recipes_raw.zip'\"), \"\\n\\ndataset_file_path \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"utils\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"get_file\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    fname\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"dataset_file_name\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    origin\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"dataset_file_origin\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    cache_dir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"CACHE_DIR\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    extract\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    archive_format\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'zip'\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_file_path\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"Here is a path to dataset file after it has been downloaded:\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"shell\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-shell\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"./tmp/datasets/recipes_raw.zip\")))), mdx(\"p\", null, \"Let's print the cache folder and see what exactly has been downloaded:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"shell\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-shell\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"!\"), \"ls -la ./tmp/datasets/\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"total 521128\\ndrwxr-xr-x  7        224 May 13 18:10 .\\ndrwxr-xr-x  4        128 May 18 18:00 ..\\n-rw-r--r--  1      20437 May 20 06:46 LICENSE\\n-rw-r--r--  1   53355492 May 13 18:10 recipes_raw.zip\\n-rw-r--r--  1   49784325 May 20 06:46 recipes_raw_nosource_ar.json\\n-rw-r--r--  1   61133971 May 20 06:46 recipes_raw_nosource_epi.json\\n-rw-r--r--  1   93702755 May 20 06:46 recipes_raw_nosource_fn.json\")))), mdx(\"p\", null, \"As you may see, the dataset consists of \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"3\"), \" files. We need to merge information from those \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"3\"), \" files into one dataset later.\"), mdx(\"p\", null, \"Let's load datasets data from \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"json\"), \" files and preview examples from them.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"load_dataset\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"silent\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# List of dataset files we want to merge.\"), \"\\n    dataset_file_names \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'recipes_raw_nosource_ar.json'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'recipes_raw_nosource_epi.json'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'recipes_raw_nosource_fn.json'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    dataset \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" dataset_file_name \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_file_names\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        dataset_file_path \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string-interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"f'\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"CACHE_DIR\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"/datasets/\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"dataset_file_name\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"'\")), \"\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"with\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"open\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_file_path\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" dataset_file\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            json_data_dict \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" json\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"load\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_file\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            json_data_list \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"list\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"json_data_dict\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"values\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            dict_keys \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"key \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" key \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n            dict_keys\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sort\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            dataset \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" json_data_list\\n\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# This code block outputs the summary for each dataset.\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" silent \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"==\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_file_path\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'==========================================='\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Number of examples: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Example object keys:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" dict_keys\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Example object:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Required keys:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'  title: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'title'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'  ingredients: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'ingredients'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'  instructions: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" json_data_list\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'instructions'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n                \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" dataset\\n\\ndataset_raw \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" load_dataset\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"./tmp/datasets/recipes_raw_nosource_ar.json\\n===========================================\\nNumber of examples:  39802\\n\\nExample object keys:\\n ['ingredients', 'instructions', 'picture_link', 'title']\\n\\nExample object:\\n {'title': 'Slow Cooker Chicken and Dumplings', 'ingredients': ['4 skinless, boneless chicken breast halves ADVERTISEMENT', '2 tablespoons butter ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of chicken soup ADVERTISEMENT', '1 onion, finely diced ADVERTISEMENT', '2 (10 ounce) packages refrigerated biscuit dough, torn into pieces ADVERTISEMENT', 'ADVERTISEMENT'], 'instructions': 'Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\\\nCover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\\\n', 'picture_link': '55lznCYBbs2mT8BTx6BTkLhynGHzM.S'}\\n\\nRequired keys:\\n\\n  title:  Slow Cooker Chicken and Dumplings\\n\\n  ingredients:  ['4 skinless, boneless chicken breast halves ADVERTISEMENT', '2 tablespoons butter ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of chicken soup ADVERTISEMENT', '1 onion, finely diced ADVERTISEMENT', '2 (10 ounce) packages refrigerated biscuit dough, torn into pieces ADVERTISEMENT', 'ADVERTISEMENT']\\n\\n  instructions:  Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\nCover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\n\\n\\n\\n\\n./tmp/datasets/recipes_raw_nosource_epi.json\\n===========================================\\nNumber of examples:  25323\\n\\nExample object keys:\\n ['ingredients', 'instructions', 'picture_link', 'title']\\n\\nExample object:\\n {'ingredients': ['12 egg whites', '12 egg yolks', '1 1/2 cups sugar', '3/4 cup rye whiskey', '12 egg whites', '3/4 cup brandy', '1/2 cup rum', '1 to 2 cups heavy cream, lightly whipped', 'Garnish: ground nutmeg'], 'picture_link': None, 'instructions': 'Beat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\\\\nBeat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.', 'title': 'Christmas Eggnog '}\\n\\nRequired keys:\\n\\n  title:  Christmas Eggnog\\n\\n  ingredients:  ['12 egg whites', '12 egg yolks', '1 1/2 cups sugar', '3/4 cup rye whiskey', '12 egg whites', '3/4 cup brandy', '1/2 cup rum', '1 to 2 cups heavy cream, lightly whipped', 'Garnish: ground nutmeg']\\n\\n  instructions:  Beat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\\nBeat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\\n\\n\\n\\n./tmp/datasets/recipes_raw_nosource_fn.json\\n===========================================\\nNumber of examples:  60039\\n\\nExample object keys:\\n ['ingredients', 'instructions', 'picture_link', 'title']\\n\\nExample object:\\n {'instructions': 'Toss ingredients lightly and spoon into a buttered baking dish. Top with additional crushed cracker crumbs, and brush with melted butter. Bake in a preheated at 350 degrees oven for 25 to 30 minutes or until delicately browned.', 'ingredients': ['1/2 cup celery, finely chopped', '1 small green pepper finely chopped', '1/2 cup finely sliced green onions', '1/4 cup chopped parsley', '1 pound crabmeat', '1 1/4 cups coarsely crushed cracker crumbs', '1/2 teaspoon salt', '3/4 teaspoons dry mustard', 'Dash hot sauce', '1/4 cup heavy cream', '1/2 cup melted butter'], 'title': \\\"Grammie Hamblet's Deviled Crab\\\", 'picture_link': None}\\n\\nRequired keys:\\n\\n  title:  Grammie Hamblet's Deviled Crab\\n\\n  ingredients:  ['1/2 cup celery, finely chopped', '1 small green pepper finely chopped', '1/2 cup finely sliced green onions', '1/4 cup chopped parsley', '1 pound crabmeat', '1 1/4 cups coarsely crushed cracker crumbs', '1/2 teaspoon salt', '3/4 teaspoons dry mustard', 'Dash hot sauce', '1/4 cup heavy cream', '1/2 cup melted butter']\\n\\n  instructions:  Toss ingredients lightly and spoon into a buttered baking dish. Top with additional crushed cracker crumbs, and brush with melted butter. Bake in a preheated at 350 degrees oven for 25 to 30 minutes or until delicately browned.\")))), mdx(\"p\", null, \"Let's count the total number of examples after we merged the files:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Total number of raw examples: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_raw\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Total number of raw examples:  125164\")))), mdx(\"h2\", {\n    \"id\": \"preprocessing-the-dataset\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Preprocessing the dataset\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#preprocessing-the-dataset\",\n    \"aria-label\": \"preprocessing the dataset permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"h3\", {\n    \"id\": \"filtering-out-incomplete-examples\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Filtering out incomplete examples\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#filtering-out-incomplete-examples\",\n    \"aria-label\": \"filtering out incomplete examples permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"It is possible that some recipes don't have some required fields (\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"name\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"ingredients\"), \" or \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"instructions\"), \"). We need to clean our dataset from those incomplete examples.\"), mdx(\"p\", null, \"The following function will help us filter out recipes which don't have either title or ingredients or instructions:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"recipe_validate_required_fields\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    required_keys \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'title'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'ingredients'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'instructions'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"not\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" required_key \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" required_keys\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"not\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"required_key\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), \"\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"type\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"required_key\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"==\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"list\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"and\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"required_key\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"==\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\")))), mdx(\"p\", null, \"Let's do the filtering now using \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"recipe_validate_required_fields()\"), \" function:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset_validated \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_raw \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" recipe_validate_required_fields\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Dataset size BEFORE validation'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_raw\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Dataset size AFTER validation'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_validated\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Number of incomplete recipes'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_raw\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_validated\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Dataset size BEFORE validation 125164\\nDataset size AFTER validation 122938\\nNumber of incomplete recipes 2226\")))), mdx(\"p\", null, \"As you may see among \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"125164\"), \" recipes we had \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2226\"), \" somehow incomplete.\"), mdx(\"h3\", {\n    \"id\": \"converting-recipes-objects-into-strings\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Converting recipes objects into strings\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#converting-recipes-objects-into-strings\",\n    \"aria-label\": \"converting recipes objects into strings permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"RNN doesn't understand objects. Therefore, we need to convert recipes objects to string and then to numbers (indices). Let's start with converting recipes objects to strings.\"), mdx(\"p\", null, \"To help our RNN learn the structure of the text faster let's add 3 \\\"landmarks\\\" to it. We will use these unique \\\"title\\\", \\\"ingredients\\\" and \\\"instruction\\\" landmarks to separate the logic sections of each recipe.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"STOP_WORD_TITLE \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\uD83D\\uDCD7 '\"), \"\\nSTOP_WORD_INGREDIENTS \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n\\uD83E\\uDD55\\\\n\\\\n'\"), \"\\nSTOP_WORD_INSTRUCTIONS \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n\\uD83D\\uDCDD\\\\n\\\\n'\")))), mdx(\"p\", null, \"The following function converts the recipe object to a string (sequence of characters) for later usage in RNN input.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"recipe_to_string\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# This string is presented as a part of recipes so we need to clean it up.\"), \"\\n    noize_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'ADVERTISEMENT'\"), \"\\n\\n    title \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'title'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    ingredients \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'ingredients'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    instructions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'instructions'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"split\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    ingredients_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" ingredient \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" ingredients\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        ingredient \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" ingredient\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"replace\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"noize_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" ingredient\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            ingredients_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string-interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"f'\\u2022 \"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"ingredient\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"\\\\n'\")), \"\\n\\n    instructions_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" instruction \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" instructions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        instruction \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" instruction\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"replace\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"noize_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" instruction\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            instructions_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string-interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"f'\\u25AA\\uFE0E \"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"instruction\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"\\\\n'\")), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string-interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"f'\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"STOP_WORD_TITLE\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"title\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"\\\\n\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"STOP_WORD_INGREDIENTS\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"ingredients_string\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"STOP_WORD_INSTRUCTIONS\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"instructions_string\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"'\"))))), mdx(\"p\", null, \"Let's apply \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"recipe_to_string()\"), \" function to \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"dataset_validated\"), \":\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset_stringified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"recipe_to_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_validated\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Stringified dataset size: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Stringified dataset size:  122938\")))), mdx(\"p\", null, \"Let's preview first several recipes:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" recipe_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"enumerate\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Recipe #{}\\\\n---------'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_index \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Recipe #1\\n---------\\n\\uD83D\\uDCD7 Slow Cooker Chicken and Dumplings\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 4 skinless, boneless chicken breast halves\\n\\u2022 2 tablespoons butter\\n\\u2022 2 (10.75 ounce) cans condensed cream of chicken soup\\n\\u2022 1 onion, finely diced\\n\\u2022 2 (10 ounce) packages refrigerated biscuit dough, torn into pieces\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\n\\u25AA\\uFE0E Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\n\\n\\n\\nRecipe #2\\n---------\\n\\uD83D\\uDCD7 Awesome Slow Cooker Pot Roast\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 2 (10.75 ounce) cans condensed cream of mushroom soup\\n\\u2022 1 (1 ounce) package dry onion soup mix\\n\\u2022 1 1/4 cups water\\n\\u2022 5 1/2 pounds pot roast\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E In a slow cooker, mix cream of mushroom soup, dry onion soup mix and water. Place pot roast in slow cooker and coat with soup mixture.\\n\\u25AA\\uFE0E Cook on High setting for 3 to 4 hours, or on Low setting for 8 to 9 hours.\\n\\n\\n\\nRecipe #3\\n---------\\n\\uD83D\\uDCD7 Brown Sugar Meatloaf\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1/2 cup packed brown sugar\\n\\u2022 1/2 cup ketchup\\n\\u2022 1 1/2 pounds lean ground beef\\n\\u2022 3/4 cup milk\\n\\u2022 2 eggs\\n\\u2022 1 1/2 teaspoons salt\\n\\u2022 1/4 teaspoon ground black pepper\\n\\u2022 1 small onion, chopped\\n\\u2022 1/4 teaspoon ground ginger\\n\\u2022 3/4 cup finely crushed saltine cracker crumbs\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat oven to 350 degrees F (175 degrees C). Lightly grease a 5x9 inch loaf pan.\\n\\u25AA\\uFE0E Press the brown sugar in the bottom of the prepared loaf pan and spread the ketchup over the sugar.\\n\\u25AA\\uFE0E In a mixing bowl, mix thoroughly all remaining ingredients and shape into a loaf. Place on top of the ketchup.\\n\\u25AA\\uFE0E Bake in preheated oven for 1 hour or until juices are clear.\")))), mdx(\"p\", null, \"Just out of curiosity let's preview the recipe somewhere from the middle of the dataset to see that it has expected data structure:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50000\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7 Herbed Bean Rago\\xFBt\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 6 ounces haricots verts (French thin green beans), trimmed and halved crosswise\\n\\u2022 1 (1-pound) bag frozen edamame (soybeans in the pod) or 1 1/4 cups frozen shelled edamame, not thawed\\n\\u2022 2/3 cup finely chopped onion\\n\\u2022 2 garlic cloves, minced\\n\\u2022 1 Turkish bay leaf or 1/2 California bay leaf\\n\\u2022 2 (3-inch) fresh rosemary sprigs\\n\\u2022 1/2 teaspoon salt\\n\\u2022 1/4 teaspoon black pepper\\n\\u2022 1 tablespoon olive oil\\n\\u2022 1 medium carrot, cut into 1/8-inch dice\\n\\u2022 1 medium celery rib, cut into 1/8-inch dice\\n\\u2022 1 (15- to 16-ounces) can small white beans, rinsed and drained\\n\\u2022 1 1/2 cups chicken stock or low-sodium broth\\n\\u2022 2 tablespoons unsalted butter\\n\\u2022 2 tablespoons finely chopped fresh flat-leaf parsley\\n\\u2022 1 tablespoon finely chopped fresh chervil (optional)\\n\\u2022 Garnish: fresh chervil sprigs\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Cook haricots verts in a large pot of boiling salted water until just tender, 3 to 4 minutes. Transfer with a slotted spoon to a bowl of ice and cold water, then drain. Add edamame to boiling water and cook 4 minutes. Drain in a colander, then rinse under cold water. If using edamame in pods, shell them and discard pods. Cook onion, garlic, bay leaf, rosemary, salt, and pepper in oil in a 2- to 4-quart heavy saucepan over moderately low heat, stirring, until softened, about 3 minutes. Add carrot and celery and cook, stirring, until softened, about 3 minutes. Add white beans and stock and simmer, covered, stirring occasionally, 10 minutes. Add haricots verts and edamame and simmer, uncovered, until heated through, 2 to 3 minutes. Add butter, parsley, and chervil (if using) and stir gently until butter is melted. Discard bay leaf and rosemary sprigs.\\n\\u25AA\\uFE0E Cook haricots verts in a large pot of boiling salted water until just tender, 3 to 4 minutes. Transfer with a slotted spoon to a bowl of ice and cold water, then drain.\\n\\u25AA\\uFE0E Add edamame to boiling water and cook 4 minutes. Drain in a colander, then rinse under cold water. If using edamame in pods, shell them and discard pods.\\n\\u25AA\\uFE0E Cook onion, garlic, bay leaf, rosemary, salt, and pepper in oil in a 2- to 4-quart heavy saucepan over moderately low heat, stirring, until softened, about 3 minutes. Add carrot and celery and cook, stirring, until softened, about 3 minutes.\\n\\u25AA\\uFE0E Add white beans and stock and simmer, covered, stirring occasionally, 10 minutes. Add haricots verts and edamame and simmer, uncovered, until heated through, 2 to 3 minutes. Add butter, parsley, and chervil (if using) and stir gently until butter is melted. Discard bay leaf and rosemary sprigs.\")))), mdx(\"h3\", {\n    \"id\": \"filtering-out-large-recipes\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Filtering out large recipes\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#filtering-out-large-recipes\",\n    \"aria-label\": \"filtering out large recipes permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Recipes have different lengths. We need to have one \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"hard-coded sequence length\"), \" limit before feeding recipe sequences to RNN. We need to find out what recipe length will cover most of the recipe use-cases and at the same time we want to keep it as small as possible to speed up the training process.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"recipes_lengths \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    recipes_lengths\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nplt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"hist\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipes_lengths\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" bins\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nplt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"show\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"388px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"64%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABuElEQVQ4y62TSy8DURTHr1A2BBFNECRW+AQisfYFLCQeGxYSwc4HICkWggULWwkLQYqI1qOhkdajwkIyGmEwrbkznRGmnZKauc4prUdEFCc5OTPnf+8v59xzL2GMpQVESoRAYPiSqvuapm2Gw+GtVBz2uCKRyJ4kSePENjhkASgJqbfubb/M/mK6rh+SQqu1lBBSIEohh4ujzDDMR9M0n1L0RwRClW6Ctu72EklRnS5OYrgARYg/riyxB4A7pAgMmLmiHFr7F2BzS2smnqGu3TsnXGdMUPW4aPwWWFlVnQsVpke0O2f/8gk7l8N/AxaXVeQDMOv06matcdLD6H00Cfxp2x+ADW1dlhi0fBGUnfUjW2z3XEHRhGmnYm/AvILCEhzKtSiv1g5ssDnf9QNosZhhxDDC4mT85vsheW3wpTh8fiLQ0E6NbZ11TB3E24AKWaLj961/dQyJXDQaPYoD8S56fce2ur5Fh7VzZnbM7ln18wH7jUjtlzzvUBRlQRCEFXRVVed5yFFKl2RZtvMv+lwwGNzkOG4UgaS9pzcNY9MeI+Xd08jPxn90sLzXaMHhvc990jPAc54BsHVwLvoOlcwAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Recipes lengths 1\",\n    \"title\": \"Recipes lengths 1\",\n    \"src\": \"/static/42704f5abc08216d5d26d0c9347b62e2/96c67/2.png\",\n    \"srcSet\": [\"/static/42704f5abc08216d5d26d0c9347b62e2/63868/2.png 250w\", \"/static/42704f5abc08216d5d26d0c9347b62e2/96c67/2.png 388w\"],\n    \"sizes\": \"(max-width: 388px) 100vw, 388px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Most of the recipes have length less than \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"5000\"), \" characters. Let's zoom in to see more detailed picture:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"hist\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipes_lengths\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"8000\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" bins\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nplt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"show\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"387px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"64.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACNUlEQVQ4y42Tz2sTQRTHR1GRYqNtqkXBKoonDZg/QAiEHARzDQQEDyIBRbcW8SdUvXlpoYJ6U0sSU7GQBrVV0Si7ovSHraAHNV2ISTHpZnebXVMTs7vznJmmbFRod+DLmx3e++z3zQ+0lQyEUHsmkzmqKMqd2XyhTyrJ/WTuWLIs96mqeiubzZ5Efr/fBQBoXpJSJMLt9DcQ53U6BdM0wbKsVUXzMMZQLpenkNfrbScO15VkeZBCjt0dryYmcnUyrZsWZtGBqrRW1/UXyOPxdFCgtqBGa3UTDlx9ZvSmPmPm0MLszw5k0nxN09LI5/O5CBAtqEqMWIKD158bhwd4BmwuWmn8BSR72Ep4LT/LaryoVZnDrvOP8dfi0j5a1sqw/4ChUKiFANfgqhZ/L8rQ0T1idPakcGL8O/zbtiNgOBymQAQ1PUaB23pShpsbwWeHZliyQU7Rbt8BMBAIsJbxLy0+lVWZQ9ryviujsNy2YTZDbbdN0QZGIpGN1CEBRpPTc9B2Jlnbe+mp6eaS5vH7EzSRiRUR0Wg1Ira/fzeAL1EwGNxEeOuhvjh8Y+wLuE4nYc/lMdh9cRS2n3sCpx7MwKy0CKsfDUClUnmH6CuhKubEa72PJiddkdjrXd1Db3dyD/kuLiG0nojy+y8MC9ygINxLfxJefRSF6cwcL+aLQr4g8bkfklCQSm8UVf1Ant5NBjviP7SWuNyAlgZ1TC87vZ/uHQi1IVv0VW1paDmHrm8m6qTrfwDIpBtsvkPq9QAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Recipes lengths 2\",\n    \"title\": \"Recipes lengths 2\",\n    \"src\": \"/static/3cc69385b2215b463ccdb324f0724a68/691c3/3.png\",\n    \"srcSet\": [\"/static/3cc69385b2215b463ccdb324f0724a68/63868/3.png 250w\", \"/static/3cc69385b2215b463ccdb324f0724a68/691c3/3.png 387w\"],\n    \"sizes\": \"(max-width: 387px) 100vw, 387px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Looks like a limit of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2000\"), \" characters for the recipes will cover most of the cases. We may try to train RNN with this maximum recipe length limit.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"MAX_RECIPE_LENGTH \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2000\")))), mdx(\"p\", null, \"Therefore, let's filter out all the recipes that are longer than \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"MAX_RECIPE_LENGTH\"), \":\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"filter_recipes_by_length\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_test\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_test\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"<=\"), \" MAX_RECIPE_LENGTH\\n\\ndataset_filtered \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"recipe_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_stringified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" filter_recipes_by_length\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Dataset size BEFORE filtering: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Dataset size AFTER filtering: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_filtered\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Number of eliminated recipes: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_filtered\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Dataset size BEFORE filtering:  122938\\nDataset size AFTER filtering:  100212\\nNumber of eliminated recipes:  22726\")))), mdx(\"p\", null, \"We lost \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"22726\"), \" recipes during this filtering but now recipes' data is more dense.\"), mdx(\"h3\", {\n    \"id\": \"summarizing-dataset-parameters\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Summarizing dataset parameters\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#summarizing-dataset-parameters\",\n    \"aria-label\": \"summarizing dataset parameters permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"TOTAL_RECIPES_NUM \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_filtered\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'MAX_RECIPE_LENGTH: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" MAX_RECIPE_LENGTH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'TOTAL_RECIPES_NUM: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" TOTAL_RECIPES_NUM\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"MAX_RECIPE_LENGTH:  2000\\nTOTAL_RECIPES_NUM:  100212\")))), mdx(\"p\", null, \"Finally, we ended up with \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"~100k\"), \" recipes. Each recipe has \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2000\"), \" characters length.\"), mdx(\"h2\", {\n    \"id\": \"creating-vocabulary\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating vocabulary\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#creating-vocabulary\",\n    \"aria-label\": \"creating vocabulary permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Recurrent neural network doesn't understand characters or words. It understands numbers instead. Therefore, we need to convert recipe texts to numbers.\"), mdx(\"p\", null, \"In this experiment we're going to use a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"character-level\"), \" language model based on multi-layer LSTM (Long Short-Term Memory) network (as opposed to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"word-level\"), \" language model). It means that instead of creating unique indices for words we will create unique indices for characters. By doing that we let the network predict the next \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"character\"), \" instead of the next \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"word\"), \" in a sequence.\"), mdx(\"p\", null, \"\\u2139\\uFE0F You may find more details about character-level RNNs explanation in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\"\n  }, \"Unreasonable Effectiveness of Recurrent Neural Networks\"), \" article by \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Andrej Karpathy\"), \":\"), mdx(\"p\", null, \"To create a vocabulary out of recipes texts we will use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\"\n  }, \"tf.keras.preprocessing.text.Tokenizer\"), \".\"), mdx(\"p\", null, \"We also need to come with some unique character that will be treated as a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"stop-character\"), \" and will indicate the end of a recipe. We need it for recipe generation afterwards since without this stop-character we won't know where the end of a recipe that we're generating is.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"STOP_SIGN \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\u2423'\"), \"\\n\\ntokenizer \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"preprocessing\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    char_level\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    filters\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    lower\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"False\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    split\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Stop word is not a part of recipes, but tokenizer must know about it as well.\"), \"\\ntokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"fit_on_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"STOP_SIGN\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\ntokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"fit_on_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_filtered\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\ntokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"get_config\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"{'num_words': None,\\n 'filters': '',\\n 'lower': False,\\n 'split': '',\\n 'char_level': True,\\n 'oov_token': None,\\n 'document_count': 100213,\\n\\n 'word_counts': '{\\\"\\\\\\\\u2423\\\": 1, \\\"\\\\\\\\ud83d\\\\\\\\udcd7\\\": 100212, \\\" \\\": 17527888, \\\"S\\\": 270259, \\\"l\\\": 3815150, \\\"o\\\": 5987496, \\\"w\\\": 964459, \\\"C\\\": 222831, \\\"k\\\": 890982, \\\"e\\\": 9296022, \\\"r\\\": 4760887, \\\"h\\\": 2922100, \\\"i\\\": 4911812, \\\"c\\\": 2883507, \\\"n\\\": 5304396, \\\"a\\\": 6067157, \\\"d\\\": 3099679, \\\"D\\\": 63999, \\\"u\\\": 2717050, \\\"m\\\": 1794411, \\\"p\\\": 2679164, \\\"g\\\": 1698670, \\\"s\\\": 4704222, \\\"\\\\\\\\n\\\": 1955281, \\\"\\\\\\\\ud83e\\\\\\\\udd55\\\": 100212, \\\"\\\\\\\\u2022\\\": 922813, \\\"4\\\": 232607, \\\",\\\": 1130487, \\\"b\\\": 1394803, \\\"t\\\": 5997722, \\\"v\\\": 746785, \\\"2\\\": 493933, \\\"(\\\": 144985, \\\"1\\\": 853931, \\\"0\\\": 145119, \\\".\\\": 1052548, \\\"7\\\": 31098, \\\"5\\\": 154071, \\\")\\\": 144977, \\\"f\\\": 1042981, \\\"y\\\": 666553, \\\"\\\\\\\\ud83d\\\\\\\\udcdd\\\": 100212, \\\"\\\\\\\\u25aa\\\": 331058, \\\"\\\\\\\\ufe0e\\\": 331058, \\\"P\\\": 200597, \\\"6\\\": 51398, \\\"H\\\": 43936, \\\"A\\\": 134274, \\\"3\\\": 213519, \\\"R\\\": 101253, \\\"x\\\": 201286, \\\"/\\\": 345257, \\\"I\\\": 81591, \\\"L\\\": 46138, \\\"8\\\": 55352, \\\"9\\\": 17697, \\\"B\\\": 123813, \\\"M\\\": 78684, \\\"F\\\": 104359, \\\"j\\\": 110008, \\\"-\\\": 219160, \\\"W\\\": 61616, \\\"\\\\\\\\u00ae\\\": 10159, \\\"N\\\": 12808, \\\"q\\\": 69654, \\\"T\\\": 101371, \\\";\\\": 72045, \\\"\\\\'\\\": 26831, \\\"Z\\\": 2428, \\\"z\\\": 115883, \\\"G\\\": 52043, \\\":\\\": 31318, \\\"E\\\": 18582, \\\"K\\\": 18421, \\\"X\\\": 385, \\\"\\\\\\\\\\\"\\\": 6445, \\\"O\\\": 28971, \\\"Y\\\": 6064, \\\"\\\\\\\\u2122\\\": 538, \\\"Q\\\": 3904, \\\"J\\\": 10269, \\\"!\\\": 3014, \\\"U\\\": 14132, \\\"V\\\": 12172, \\\"&\\\": 1039, \\\"+\\\": 87, \\\"=\\\": 113, \\\"%\\\": 993, \\\"*\\\": 3243, \\\"\\\\\\\\u00a9\\\": 99, \\\"[\\\": 30, \\\"]\\\": 31, \\\"\\\\\\\\u00e9\\\": 6727, \\\"<\\\": 76, \\\">\\\": 86, \\\"\\\\\\\\u00bd\\\": 166, \\\"#\\\": 168, \\\"\\\\\\\\u00f1\\\": 891, \\\"?\\\": 327, \\\"\\\\\\\\u2019\\\": 111, \\\"\\\\\\\\u00b0\\\": 6808, \\\"\\\\\\\\u201d\\\": 6, \\\"$\\\": 84, \\\"@\\\": 5, \\\"{\\\": 8, \\\"}\\\": 9, \\\"\\\\\\\\u2013\\\": 1228, \\\"\\\\\\\\u0096\\\": 7, \\\"\\\\\\\\u00e0\\\": 26, \\\"\\\\\\\\u00e2\\\": 106, \\\"\\\\\\\\u00e8\\\": 846, \\\"\\\\\\\\u00e1\\\": 74, \\\"\\\\\\\\u2014\\\": 215, \\\"\\\\\\\\u2044\\\": 16, \\\"\\\\\\\\u00ee\\\": 415, \\\"\\\\\\\\u00e7\\\": 171, \\\"_\\\": 26, \\\"\\\\\\\\u00fa\\\": 48, \\\"\\\\\\\\u00ef\\\": 43, \\\"\\\\\\\\u201a\\\": 20, \\\"\\\\\\\\u00fb\\\": 36, \\\"\\\\\\\\u00f3\\\": 74, \\\"\\\\\\\\u00ed\\\": 130, \\\"\\\\\\\\u25ca\\\": 4, \\\"\\\\\\\\u00f9\\\": 12, \\\"\\\\\\\\u00d7\\\": 6, \\\"\\\\\\\\u00ec\\\": 8, \\\"\\\\\\\\u00fc\\\": 29, \\\"\\\\\\\\u2031\\\": 4, \\\"\\\\\\\\u00ba\\\": 19, \\\"\\\\\\\\u201c\\\": 4, \\\"\\\\\\\\u00ad\\\": 25, \\\"\\\\\\\\u00ea\\\": 27, \\\"\\\\\\\\u00f6\\\": 9, \\\"\\\\\\\\u0301\\\": 11, \\\"\\\\\\\\u00f4\\\": 8, \\\"\\\\\\\\u00c1\\\": 2, \\\"\\\\\\\\u00be\\\": 23, \\\"\\\\\\\\u00bc\\\": 95, \\\"\\\\\\\\u00eb\\\": 2, \\\"\\\\\\\\u0097\\\": 2, \\\"\\\\\\\\u215b\\\": 3, \\\"\\\\\\\\u2027\\\": 4, \\\"\\\\\\\\u00e4\\\": 15, \\\"\\\\\\\\u001a\\\": 2, \\\"\\\\\\\\u00f8\\\": 2, \\\"\\\\\\\\ufffd\\\": 20, \\\"\\\\\\\\u02da\\\": 6, \\\"\\\\\\\\u00bf\\\": 264, \\\"\\\\\\\\u2153\\\": 2, \\\"|\\\": 2, \\\"\\\\\\\\u00e5\\\": 3, \\\"\\\\\\\\u00a4\\\": 1, \\\"\\\\\\\\u201f\\\": 1, \\\"\\\\\\\\u00a7\\\": 5, \\\"\\\\\\\\ufb02\\\": 3, \\\"\\\\\\\\u00a0\\\": 1, \\\"\\\\\\\\u01b0\\\": 2, \\\"\\\\\\\\u01a1\\\": 1, \\\"\\\\\\\\u0103\\\": 1, \\\"\\\\\\\\u0300\\\": 1, \\\"\\\\\\\\u00bb\\\": 6, \\\"`\\\": 3, \\\"\\\\\\\\u0092\\\": 2, \\\"\\\\\\\\u215e\\\": 1, \\\"\\\\\\\\u202d\\\": 4, \\\"\\\\\\\\u00b4\\\": 2, \\\"\\\\\\\\u2012\\\": 2, \\\"\\\\\\\\u00c9\\\": 40, \\\"\\\\\\\\u00da\\\": 14, \\\"\\\\\\\\u20ac\\\": 1, \\\"\\\\\\\\\\\\\\\\\\\": 5, \\\"~\\\": 1, \\\"\\\\\\\\u0095\\\": 1, \\\"\\\\\\\\u00c2\\\": 2}',\\n\\n 'word_docs': '{\\\"\\\\\\\\u2423\\\": 1, \\\"k\\\": 97316, \\\"0\\\": 61954, \\\"o\\\": 100205, \\\"r\\\": 100207, \\\"d\\\": 100194, \\\"u\\\": 100161, \\\"S\\\": 89250, \\\"\\\\\\\\u25aa\\\": 100212, \\\"D\\\": 40870, \\\"1\\\": 99320, \\\"g\\\": 99975, \\\"n\\\": 100198, \\\"b\\\": 99702, \\\"t\\\": 100202, \\\".\\\": 100163, \\\" \\\": 100212, \\\"7\\\": 24377, \\\"3\\\": 79135, \\\"\\\\\\\\ud83d\\\\\\\\udcd7\\\": 100212, \\\"i\\\": 100207, \\\"5\\\": 65486, \\\"f\\\": 98331, \\\"c\\\": 100190, \\\"4\\\": 82453, \\\"a\\\": 100205, \\\"2\\\": 96743, \\\"v\\\": 97848, \\\"C\\\": 83328, \\\"s\\\": 100204, \\\"\\\\\\\\n\\\": 100212, \\\"6\\\": 35206, \\\"\\\\\\\\ud83d\\\\\\\\udcdd\\\": 100212, \\\",\\\": 98524, \\\"\\\\\\\\ufe0e\\\": 100212, \\\"l\\\": 100206, \\\"e\\\": 100212, \\\"y\\\": 96387, \\\")\\\": 67614, \\\"p\\\": 100046, \\\"H\\\": 31908, \\\"\\\\\\\\ud83e\\\\\\\\udd55\\\": 100212, \\\"m\\\": 99988, \\\"w\\\": 99227, \\\"(\\\": 67627, \\\"A\\\": 60900, \\\"h\\\": 100161, \\\"\\\\\\\\u2022\\\": 100212, \\\"P\\\": 79364, \\\"R\\\": 54040, \\\"9\\\": 14114, \\\"8\\\": 37000, \\\"L\\\": 32101, \\\"x\\\": 72133, \\\"I\\\": 46675, \\\"/\\\": 89051, \\\"j\\\": 47438, \\\"F\\\": 57940, \\\"B\\\": 64278, \\\"M\\\": 48332, \\\"-\\\": 74711, \\\"T\\\": 53758, \\\"\\\\\\\\u00ae\\\": 5819, \\\"N\\\": 9981, \\\"W\\\": 38981, \\\"q\\\": 36538, \\\";\\\": 33863, \\\"G\\\": 35355, \\\"\\\\'\\\": 18120, \\\"z\\\": 42430, \\\"Z\\\": 2184, \\\":\\\": 18214, \\\"E\\\": 12161, \\\"K\\\": 14834, \\\"X\\\": 321, \\\"\\\\\\\\\\\"\\\": 2617, \\\"O\\\": 20103, \\\"Y\\\": 5148, \\\"\\\\\\\\u2122\\\": 448, \\\"Q\\\": 3142, \\\"J\\\": 8225, \\\"!\\\": 2428, \\\"U\\\": 10621, \\\"V\\\": 9710, \\\"&\\\": 749, \\\"+\\\": 32, \\\"=\\\": 48, \\\"%\\\": 717, \\\"*\\\": 1780, \\\"\\\\\\\\u00a9\\\": 91, \\\"]\\\": 26, \\\"[\\\": 25, \\\"\\\\\\\\u00e9\\\": 2462, \\\">\\\": 33, \\\"<\\\": 27, \\\"\\\\\\\\u00bd\\\": 81, \\\"#\\\": 139, \\\"\\\\\\\\u00f1\\\": 423, \\\"?\\\": 207, \\\"\\\\\\\\u2019\\\": 64, \\\"\\\\\\\\u00b0\\\": 3062, \\\"\\\\\\\\u201d\\\": 3, \\\"@\\\": 4, \\\"$\\\": 49, \\\"{\\\": 7, \\\"}\\\": 8, \\\"\\\\\\\\u2013\\\": 491, \\\"\\\\\\\\u0096\\\": 7, \\\"\\\\\\\\u00e0\\\": 22, \\\"\\\\\\\\u00e2\\\": 45, \\\"\\\\\\\\u00e8\\\": 335, \\\"\\\\\\\\u00e1\\\": 38, \\\"\\\\\\\\u2014\\\": 95, \\\"\\\\\\\\u2044\\\": 9, \\\"\\\\\\\\u00ee\\\": 122, \\\"\\\\\\\\u00e7\\\": 120, \\\"_\\\": 8, \\\"\\\\\\\\u00fa\\\": 25, \\\"\\\\\\\\u00ef\\\": 24, \\\"\\\\\\\\u201a\\\": 10, \\\"\\\\\\\\u00fb\\\": 29, \\\"\\\\\\\\u00f3\\\": 40, \\\"\\\\\\\\u00ed\\\": 52, \\\"\\\\\\\\u25ca\\\": 2, \\\"\\\\\\\\u00f9\\\": 6, \\\"\\\\\\\\u00d7\\\": 4, \\\"\\\\\\\\u00ec\\\": 4, \\\"\\\\\\\\u00fc\\\": 19, \\\"\\\\\\\\u2031\\\": 2, \\\"\\\\\\\\u00ba\\\": 9, \\\"\\\\\\\\u201c\\\": 2, \\\"\\\\\\\\u00ad\\\": 11, \\\"\\\\\\\\u00ea\\\": 4, \\\"\\\\\\\\u00f6\\\": 4, \\\"\\\\\\\\u0301\\\": 6, \\\"\\\\\\\\u00f4\\\": 5, \\\"\\\\\\\\u00c1\\\": 2, \\\"\\\\\\\\u00be\\\": 18, \\\"\\\\\\\\u00bc\\\": 55, \\\"\\\\\\\\u00eb\\\": 2, \\\"\\\\\\\\u0097\\\": 1, \\\"\\\\\\\\u215b\\\": 2, \\\"\\\\\\\\u2027\\\": 3, \\\"\\\\\\\\u00e4\\\": 8, \\\"\\\\\\\\u001a\\\": 1, \\\"\\\\\\\\u00f8\\\": 1, \\\"\\\\\\\\ufffd\\\": 4, \\\"\\\\\\\\u02da\\\": 3, \\\"\\\\\\\\u00bf\\\": 191, \\\"\\\\\\\\u2153\\\": 1, \\\"|\\\": 2, \\\"\\\\\\\\u00e5\\\": 1, \\\"\\\\\\\\u00a4\\\": 1, \\\"\\\\\\\\u201f\\\": 1, \\\"\\\\\\\\u00a7\\\": 3, \\\"\\\\\\\\ufb02\\\": 1, \\\"\\\\\\\\u0300\\\": 1, \\\"\\\\\\\\u01a1\\\": 1, \\\"\\\\\\\\u00a0\\\": 1, \\\"\\\\\\\\u01b0\\\": 1, \\\"\\\\\\\\u0103\\\": 1, \\\"\\\\\\\\u00bb\\\": 2, \\\"`\\\": 3, \\\"\\\\\\\\u0092\\\": 2, \\\"\\\\\\\\u215e\\\": 1, \\\"\\\\\\\\u202d\\\": 1, \\\"\\\\\\\\u00b4\\\": 1, \\\"\\\\\\\\u2012\\\": 1, \\\"\\\\\\\\u00c9\\\": 15, \\\"\\\\\\\\u00da\\\": 5, \\\"\\\\\\\\u20ac\\\": 1, \\\"\\\\\\\\\\\\\\\\\\\": 5, \\\"~\\\": 1, \\\"\\\\\\\\u0095\\\": 1, \\\"\\\\\\\\u00c2\\\": 1}',\\n\\n 'index_docs': '{\\\"1\\\": 100212, \\\"165\\\": 1, \\\"25\\\": 97316, \\\"41\\\": 61954, \\\"5\\\": 100205, \\\"8\\\": 100207, \\\"11\\\": 100194, \\\"14\\\": 100161, \\\"33\\\": 89250, \\\"31\\\": 100212, \\\"58\\\": 40870, \\\"26\\\": 99320, \\\"18\\\": 99975, \\\"6\\\": 100198, \\\"19\\\": 99702, \\\"4\\\": 100202, \\\"21\\\": 100163, \\\"66\\\": 24377, \\\"37\\\": 79135, \\\"51\\\": 100212, \\\"7\\\": 100207, \\\"40\\\": 65486, \\\"22\\\": 98331, \\\"13\\\": 100190, \\\"34\\\": 82453, \\\"3\\\": 100205, \\\"29\\\": 96743, \\\"27\\\": 97848, \\\"35\\\": 83328, \\\"9\\\": 100204, \\\"16\\\": 100212, \\\"62\\\": 35206, \\\"53\\\": 100212, \\\"20\\\": 98524, \\\"32\\\": 100212, \\\"10\\\": 100206, \\\"2\\\": 100212, \\\"28\\\": 96387, \\\"43\\\": 67614, \\\"15\\\": 100046, \\\"64\\\": 31908, \\\"52\\\": 100212, \\\"17\\\": 99988, \\\"23\\\": 99227, \\\"42\\\": 67627, \\\"44\\\": 60900, \\\"12\\\": 100161, \\\"24\\\": 100212, \\\"39\\\": 79364, \\\"50\\\": 54040, \\\"71\\\": 14114, \\\"60\\\": 37000, \\\"63\\\": 32101, \\\"38\\\": 72133, \\\"54\\\": 46675, \\\"30\\\": 89051, \\\"47\\\": 47438, \\\"48\\\": 57940, \\\"45\\\": 64278, \\\"55\\\": 48332, \\\"36\\\": 74711, \\\"49\\\": 53758, \\\"76\\\": 5819, \\\"73\\\": 9981, \\\"59\\\": 38981, \\\"57\\\": 36538, \\\"56\\\": 33863, \\\"61\\\": 35355, \\\"68\\\": 18120, \\\"46\\\": 42430, \\\"84\\\": 2184, \\\"65\\\": 18214, \\\"69\\\": 12161, \\\"70\\\": 14834, \\\"92\\\": 321, \\\"79\\\": 2617, \\\"67\\\": 20103, \\\"80\\\": 5148, \\\"90\\\": 448, \\\"81\\\": 3142, \\\"75\\\": 8225, \\\"83\\\": 2428, \\\"72\\\": 10621, \\\"74\\\": 9710, \\\"86\\\": 749, \\\"105\\\": 32, \\\"100\\\": 48, \\\"87\\\": 717, \\\"82\\\": 1780, \\\"103\\\": 91, \\\"115\\\": 26, \\\"116\\\": 25, \\\"78\\\": 2462, \\\"106\\\": 33, \\\"108\\\": 27, \\\"98\\\": 81, \\\"97\\\": 139, \\\"88\\\": 423, \\\"93\\\": 207, \\\"101\\\": 64, \\\"77\\\": 3062, \\\"137\\\": 3, \\\"141\\\": 4, \\\"107\\\": 49, \\\"133\\\": 7, \\\"131\\\": 8, \\\"85\\\": 491, \\\"136\\\": 7, \\\"119\\\": 22, \\\"102\\\": 45, \\\"89\\\": 335, \\\"109\\\": 38, \\\"95\\\": 95, \\\"126\\\": 9, \\\"91\\\": 122, \\\"96\\\": 120, \\\"120\\\": 8, \\\"111\\\": 25, \\\"112\\\": 24, \\\"123\\\": 10, \\\"114\\\": 29, \\\"110\\\": 40, \\\"99\\\": 52, \\\"144\\\": 2, \\\"129\\\": 6, \\\"138\\\": 4, \\\"134\\\": 4, \\\"117\\\": 19, \\\"145\\\": 2, \\\"125\\\": 9, \\\"146\\\": 2, \\\"121\\\": 11, \\\"118\\\": 4, \\\"132\\\": 4, \\\"130\\\": 6, \\\"135\\\": 5, \\\"153\\\": 2, \\\"122\\\": 18, \\\"104\\\": 55, \\\"154\\\": 2, \\\"155\\\": 1, \\\"149\\\": 2, \\\"147\\\": 3, \\\"127\\\": 8, \\\"156\\\": 1, \\\"157\\\": 1, \\\"124\\\": 4, \\\"139\\\": 3, \\\"94\\\": 191, \\\"158\\\": 1, \\\"159\\\": 2, \\\"150\\\": 1, \\\"166\\\": 1, \\\"167\\\": 1, \\\"142\\\": 3, \\\"151\\\": 1, \\\"171\\\": 1, \\\"169\\\": 1, \\\"168\\\": 1, \\\"160\\\": 1, \\\"170\\\": 1, \\\"140\\\": 2, \\\"152\\\": 3, \\\"161\\\": 2, \\\"172\\\": 1, \\\"148\\\": 1, \\\"162\\\": 1, \\\"163\\\": 1, \\\"113\\\": 15, \\\"128\\\": 5, \\\"173\\\": 1, \\\"143\\\": 5, \\\"174\\\": 1, \\\"175\\\": 1, \\\"164\\\": 1}',\\n\\n 'index_word': '{\\\"1\\\": \\\" \\\", \\\"2\\\": \\\"e\\\", \\\"3\\\": \\\"a\\\", \\\"4\\\": \\\"t\\\", \\\"5\\\": \\\"o\\\", \\\"6\\\": \\\"n\\\", \\\"7\\\": \\\"i\\\", \\\"8\\\": \\\"r\\\", \\\"9\\\": \\\"s\\\", \\\"10\\\": \\\"l\\\", \\\"11\\\": \\\"d\\\", \\\"12\\\": \\\"h\\\", \\\"13\\\": \\\"c\\\", \\\"14\\\": \\\"u\\\", \\\"15\\\": \\\"p\\\", \\\"16\\\": \\\"\\\\\\\\n\\\", \\\"17\\\": \\\"m\\\", \\\"18\\\": \\\"g\\\", \\\"19\\\": \\\"b\\\", \\\"20\\\": \\\",\\\", \\\"21\\\": \\\".\\\", \\\"22\\\": \\\"f\\\", \\\"23\\\": \\\"w\\\", \\\"24\\\": \\\"\\\\\\\\u2022\\\", \\\"25\\\": \\\"k\\\", \\\"26\\\": \\\"1\\\", \\\"27\\\": \\\"v\\\", \\\"28\\\": \\\"y\\\", \\\"29\\\": \\\"2\\\", \\\"30\\\": \\\"/\\\", \\\"31\\\": \\\"\\\\\\\\u25aa\\\", \\\"32\\\": \\\"\\\\\\\\ufe0e\\\", \\\"33\\\": \\\"S\\\", \\\"34\\\": \\\"4\\\", \\\"35\\\": \\\"C\\\", \\\"36\\\": \\\"-\\\", \\\"37\\\": \\\"3\\\", \\\"38\\\": \\\"x\\\", \\\"39\\\": \\\"P\\\", \\\"40\\\": \\\"5\\\", \\\"41\\\": \\\"0\\\", \\\"42\\\": \\\"(\\\", \\\"43\\\": \\\")\\\", \\\"44\\\": \\\"A\\\", \\\"45\\\": \\\"B\\\", \\\"46\\\": \\\"z\\\", \\\"47\\\": \\\"j\\\", \\\"48\\\": \\\"F\\\", \\\"49\\\": \\\"T\\\", \\\"50\\\": \\\"R\\\", \\\"51\\\": \\\"\\\\\\\\ud83d\\\\\\\\udcd7\\\", \\\"52\\\": \\\"\\\\\\\\ud83e\\\\\\\\udd55\\\", \\\"53\\\": \\\"\\\\\\\\ud83d\\\\\\\\udcdd\\\", \\\"54\\\": \\\"I\\\", \\\"55\\\": \\\"M\\\", \\\"56\\\": \\\";\\\", \\\"57\\\": \\\"q\\\", \\\"58\\\": \\\"D\\\", \\\"59\\\": \\\"W\\\", \\\"60\\\": \\\"8\\\", \\\"61\\\": \\\"G\\\", \\\"62\\\": \\\"6\\\", \\\"63\\\": \\\"L\\\", \\\"64\\\": \\\"H\\\", \\\"65\\\": \\\":\\\", \\\"66\\\": \\\"7\\\", \\\"67\\\": \\\"O\\\", \\\"68\\\": \\\"\\\\'\\\", \\\"69\\\": \\\"E\\\", \\\"70\\\": \\\"K\\\", \\\"71\\\": \\\"9\\\", \\\"72\\\": \\\"U\\\", \\\"73\\\": \\\"N\\\", \\\"74\\\": \\\"V\\\", \\\"75\\\": \\\"J\\\", \\\"76\\\": \\\"\\\\\\\\u00ae\\\", \\\"77\\\": \\\"\\\\\\\\u00b0\\\", \\\"78\\\": \\\"\\\\\\\\u00e9\\\", \\\"79\\\": \\\"\\\\\\\\\\\"\\\", \\\"80\\\": \\\"Y\\\", \\\"81\\\": \\\"Q\\\", \\\"82\\\": \\\"*\\\", \\\"83\\\": \\\"!\\\", \\\"84\\\": \\\"Z\\\", \\\"85\\\": \\\"\\\\\\\\u2013\\\", \\\"86\\\": \\\"&\\\", \\\"87\\\": \\\"%\\\", \\\"88\\\": \\\"\\\\\\\\u00f1\\\", \\\"89\\\": \\\"\\\\\\\\u00e8\\\", \\\"90\\\": \\\"\\\\\\\\u2122\\\", \\\"91\\\": \\\"\\\\\\\\u00ee\\\", \\\"92\\\": \\\"X\\\", \\\"93\\\": \\\"?\\\", \\\"94\\\": \\\"\\\\\\\\u00bf\\\", \\\"95\\\": \\\"\\\\\\\\u2014\\\", \\\"96\\\": \\\"\\\\\\\\u00e7\\\", \\\"97\\\": \\\"#\\\", \\\"98\\\": \\\"\\\\\\\\u00bd\\\", \\\"99\\\": \\\"\\\\\\\\u00ed\\\", \\\"100\\\": \\\"=\\\", \\\"101\\\": \\\"\\\\\\\\u2019\\\", \\\"102\\\": \\\"\\\\\\\\u00e2\\\", \\\"103\\\": \\\"\\\\\\\\u00a9\\\", \\\"104\\\": \\\"\\\\\\\\u00bc\\\", \\\"105\\\": \\\"+\\\", \\\"106\\\": \\\">\\\", \\\"107\\\": \\\"$\\\", \\\"108\\\": \\\"<\\\", \\\"109\\\": \\\"\\\\\\\\u00e1\\\", \\\"110\\\": \\\"\\\\\\\\u00f3\\\", \\\"111\\\": \\\"\\\\\\\\u00fa\\\", \\\"112\\\": \\\"\\\\\\\\u00ef\\\", \\\"113\\\": \\\"\\\\\\\\u00c9\\\", \\\"114\\\": \\\"\\\\\\\\u00fb\\\", \\\"115\\\": \\\"]\\\", \\\"116\\\": \\\"[\\\", \\\"117\\\": \\\"\\\\\\\\u00fc\\\", \\\"118\\\": \\\"\\\\\\\\u00ea\\\", \\\"119\\\": \\\"\\\\\\\\u00e0\\\", \\\"120\\\": \\\"_\\\", \\\"121\\\": \\\"\\\\\\\\u00ad\\\", \\\"122\\\": \\\"\\\\\\\\u00be\\\", \\\"123\\\": \\\"\\\\\\\\u201a\\\", \\\"124\\\": \\\"\\\\\\\\ufffd\\\", \\\"125\\\": \\\"\\\\\\\\u00ba\\\", \\\"126\\\": \\\"\\\\\\\\u2044\\\", \\\"127\\\": \\\"\\\\\\\\u00e4\\\", \\\"128\\\": \\\"\\\\\\\\u00da\\\", \\\"129\\\": \\\"\\\\\\\\u00f9\\\", \\\"130\\\": \\\"\\\\\\\\u0301\\\", \\\"131\\\": \\\"}\\\", \\\"132\\\": \\\"\\\\\\\\u00f6\\\", \\\"133\\\": \\\"{\\\", \\\"134\\\": \\\"\\\\\\\\u00ec\\\", \\\"135\\\": \\\"\\\\\\\\u00f4\\\", \\\"136\\\": \\\"\\\\\\\\u0096\\\", \\\"137\\\": \\\"\\\\\\\\u201d\\\", \\\"138\\\": \\\"\\\\\\\\u00d7\\\", \\\"139\\\": \\\"\\\\\\\\u02da\\\", \\\"140\\\": \\\"\\\\\\\\u00bb\\\", \\\"141\\\": \\\"@\\\", \\\"142\\\": \\\"\\\\\\\\u00a7\\\", \\\"143\\\": \\\"\\\\\\\\\\\\\\\\\\\", \\\"144\\\": \\\"\\\\\\\\u25ca\\\", \\\"145\\\": \\\"\\\\\\\\u2031\\\", \\\"146\\\": \\\"\\\\\\\\u201c\\\", \\\"147\\\": \\\"\\\\\\\\u2027\\\", \\\"148\\\": \\\"\\\\\\\\u202d\\\", \\\"149\\\": \\\"\\\\\\\\u215b\\\", \\\"150\\\": \\\"\\\\\\\\u00e5\\\", \\\"151\\\": \\\"\\\\\\\\ufb02\\\", \\\"152\\\": \\\"`\\\", \\\"153\\\": \\\"\\\\\\\\u00c1\\\", \\\"154\\\": \\\"\\\\\\\\u00eb\\\", \\\"155\\\": \\\"\\\\\\\\u0097\\\", \\\"156\\\": \\\"\\\\\\\\u001a\\\", \\\"157\\\": \\\"\\\\\\\\u00f8\\\", \\\"158\\\": \\\"\\\\\\\\u2153\\\", \\\"159\\\": \\\"|\\\", \\\"160\\\": \\\"\\\\\\\\u01b0\\\", \\\"161\\\": \\\"\\\\\\\\u0092\\\", \\\"162\\\": \\\"\\\\\\\\u00b4\\\", \\\"163\\\": \\\"\\\\\\\\u2012\\\", \\\"164\\\": \\\"\\\\\\\\u00c2\\\", \\\"165\\\": \\\"\\\\\\\\u2423\\\", \\\"166\\\": \\\"\\\\\\\\u00a4\\\", \\\"167\\\": \\\"\\\\\\\\u201f\\\", \\\"168\\\": \\\"\\\\\\\\u00a0\\\", \\\"169\\\": \\\"\\\\\\\\u01a1\\\", \\\"170\\\": \\\"\\\\\\\\u0103\\\", \\\"171\\\": \\\"\\\\\\\\u0300\\\", \\\"172\\\": \\\"\\\\\\\\u215e\\\", \\\"173\\\": \\\"\\\\\\\\u20ac\\\", \\\"174\\\": \\\"~\\\", \\\"175\\\": \\\"\\\\\\\\u0095\\\"}',\\n\\n 'word_index': '{\\\" \\\": 1, \\\"e\\\": 2, \\\"a\\\": 3, \\\"t\\\": 4, \\\"o\\\": 5, \\\"n\\\": 6, \\\"i\\\": 7, \\\"r\\\": 8, \\\"s\\\": 9, \\\"l\\\": 10, \\\"d\\\": 11, \\\"h\\\": 12, \\\"c\\\": 13, \\\"u\\\": 14, \\\"p\\\": 15, \\\"\\\\\\\\n\\\": 16, \\\"m\\\": 17, \\\"g\\\": 18, \\\"b\\\": 19, \\\",\\\": 20, \\\".\\\": 21, \\\"f\\\": 22, \\\"w\\\": 23, \\\"\\\\\\\\u2022\\\": 24, \\\"k\\\": 25, \\\"1\\\": 26, \\\"v\\\": 27, \\\"y\\\": 28, \\\"2\\\": 29, \\\"/\\\": 30, \\\"\\\\\\\\u25aa\\\": 31, \\\"\\\\\\\\ufe0e\\\": 32, \\\"S\\\": 33, \\\"4\\\": 34, \\\"C\\\": 35, \\\"-\\\": 36, \\\"3\\\": 37, \\\"x\\\": 38, \\\"P\\\": 39, \\\"5\\\": 40, \\\"0\\\": 41, \\\"(\\\": 42, \\\")\\\": 43, \\\"A\\\": 44, \\\"B\\\": 45, \\\"z\\\": 46, \\\"j\\\": 47, \\\"F\\\": 48, \\\"T\\\": 49, \\\"R\\\": 50, \\\"\\\\\\\\ud83d\\\\\\\\udcd7\\\": 51, \\\"\\\\\\\\ud83e\\\\\\\\udd55\\\": 52, \\\"\\\\\\\\ud83d\\\\\\\\udcdd\\\": 53, \\\"I\\\": 54, \\\"M\\\": 55, \\\";\\\": 56, \\\"q\\\": 57, \\\"D\\\": 58, \\\"W\\\": 59, \\\"8\\\": 60, \\\"G\\\": 61, \\\"6\\\": 62, \\\"L\\\": 63, \\\"H\\\": 64, \\\":\\\": 65, \\\"7\\\": 66, \\\"O\\\": 67, \\\"\\\\'\\\": 68, \\\"E\\\": 69, \\\"K\\\": 70, \\\"9\\\": 71, \\\"U\\\": 72, \\\"N\\\": 73, \\\"V\\\": 74, \\\"J\\\": 75, \\\"\\\\\\\\u00ae\\\": 76, \\\"\\\\\\\\u00b0\\\": 77, \\\"\\\\\\\\u00e9\\\": 78, \\\"\\\\\\\\\\\"\\\": 79, \\\"Y\\\": 80, \\\"Q\\\": 81, \\\"*\\\": 82, \\\"!\\\": 83, \\\"Z\\\": 84, \\\"\\\\\\\\u2013\\\": 85, \\\"&\\\": 86, \\\"%\\\": 87, \\\"\\\\\\\\u00f1\\\": 88, \\\"\\\\\\\\u00e8\\\": 89, \\\"\\\\\\\\u2122\\\": 90, \\\"\\\\\\\\u00ee\\\": 91, \\\"X\\\": 92, \\\"?\\\": 93, \\\"\\\\\\\\u00bf\\\": 94, \\\"\\\\\\\\u2014\\\": 95, \\\"\\\\\\\\u00e7\\\": 96, \\\"#\\\": 97, \\\"\\\\\\\\u00bd\\\": 98, \\\"\\\\\\\\u00ed\\\": 99, \\\"=\\\": 100, \\\"\\\\\\\\u2019\\\": 101, \\\"\\\\\\\\u00e2\\\": 102, \\\"\\\\\\\\u00a9\\\": 103, \\\"\\\\\\\\u00bc\\\": 104, \\\"+\\\": 105, \\\">\\\": 106, \\\"$\\\": 107, \\\"<\\\": 108, \\\"\\\\\\\\u00e1\\\": 109, \\\"\\\\\\\\u00f3\\\": 110, \\\"\\\\\\\\u00fa\\\": 111, \\\"\\\\\\\\u00ef\\\": 112, \\\"\\\\\\\\u00c9\\\": 113, \\\"\\\\\\\\u00fb\\\": 114, \\\"]\\\": 115, \\\"[\\\": 116, \\\"\\\\\\\\u00fc\\\": 117, \\\"\\\\\\\\u00ea\\\": 118, \\\"\\\\\\\\u00e0\\\": 119, \\\"_\\\": 120, \\\"\\\\\\\\u00ad\\\": 121, \\\"\\\\\\\\u00be\\\": 122, \\\"\\\\\\\\u201a\\\": 123, \\\"\\\\\\\\ufffd\\\": 124, \\\"\\\\\\\\u00ba\\\": 125, \\\"\\\\\\\\u2044\\\": 126, \\\"\\\\\\\\u00e4\\\": 127, \\\"\\\\\\\\u00da\\\": 128, \\\"\\\\\\\\u00f9\\\": 129, \\\"\\\\\\\\u0301\\\": 130, \\\"}\\\": 131, \\\"\\\\\\\\u00f6\\\": 132, \\\"{\\\": 133, \\\"\\\\\\\\u00ec\\\": 134, \\\"\\\\\\\\u00f4\\\": 135, \\\"\\\\\\\\u0096\\\": 136, \\\"\\\\\\\\u201d\\\": 137, \\\"\\\\\\\\u00d7\\\": 138, \\\"\\\\\\\\u02da\\\": 139, \\\"\\\\\\\\u00bb\\\": 140, \\\"@\\\": 141, \\\"\\\\\\\\u00a7\\\": 142, \\\"\\\\\\\\\\\\\\\\\\\": 143, \\\"\\\\\\\\u25ca\\\": 144, \\\"\\\\\\\\u2031\\\": 145, \\\"\\\\\\\\u201c\\\": 146, \\\"\\\\\\\\u2027\\\": 147, \\\"\\\\\\\\u202d\\\": 148, \\\"\\\\\\\\u215b\\\": 149, \\\"\\\\\\\\u00e5\\\": 150, \\\"\\\\\\\\ufb02\\\": 151, \\\"`\\\": 152, \\\"\\\\\\\\u00c1\\\": 153, \\\"\\\\\\\\u00eb\\\": 154, \\\"\\\\\\\\u0097\\\": 155, \\\"\\\\\\\\u001a\\\": 156, \\\"\\\\\\\\u00f8\\\": 157, \\\"\\\\\\\\u2153\\\": 158, \\\"|\\\": 159, \\\"\\\\\\\\u01b0\\\": 160, \\\"\\\\\\\\u0092\\\": 161, \\\"\\\\\\\\u00b4\\\": 162, \\\"\\\\\\\\u2012\\\": 163, \\\"\\\\\\\\u00c2\\\": 164, \\\"\\\\\\\\u2423\\\": 165, \\\"\\\\\\\\u00a4\\\": 166, \\\"\\\\\\\\u201f\\\": 167, \\\"\\\\\\\\u00a0\\\": 168, \\\"\\\\\\\\u01a1\\\": 169, \\\"\\\\\\\\u0103\\\": 170, \\\"\\\\\\\\u0300\\\": 171, \\\"\\\\\\\\u215e\\\": 172, \\\"\\\\\\\\u20ac\\\": 173, \\\"~\\\": 174, \\\"\\\\\\\\u0095\\\": 175}'}\")))), mdx(\"p\", null, \"To get a full size of a vocabulary we need to add \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"+1\"), \" to the number of already registered characters because \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\"\n  }, \"index \", mdx(\"code\", {\n    parentName: \"a\",\n    \"className\": \"language-text\"\n  }, \"0\"), \" is a reserved index that won't be assigned to any word\"), \".\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"VOCABULARY_SIZE \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"word_counts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'VOCABULARY_SIZE: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" VOCABULARY_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"VOCABULARY_SIZE:  176\")))), mdx(\"p\", null, \"Let's play around with tokenizer dictionaries to see how we may convert characters to indices and vice-versa:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"index_word\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"5\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"index_word\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"20\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"o\\n,\")))), mdx(\"p\", null, \"Let's try to convert character to index:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"word_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'r'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"8\")))), mdx(\"p\", null, \"To illustrate what kind of characters form all the recipes in our dataset we may print all of them as an array:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"array_vocabulary \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"word_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" word_index \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"VOCABULARY_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"char \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" char \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" array_vocabulary\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"['', ' ', 'e', 'a', 't', 'o', 'n', 'i', 'r', 's', 'l', 'd', 'h', 'c', 'u', 'p', '\\\\n', 'm', 'g', 'b', ',', '.', 'f', 'w', '\\u2022', 'k', '1', 'v', 'y', '2', '/', '\\u25AA', '\\uFE0E', 'S', '4', 'C', '-', '3', 'x', 'P', '5', '0', '(', ')', 'A', 'B', 'z', 'j', 'F', 'T', 'R', '\\uD83D\\uDCD7', '\\uD83E\\uDD55', '\\uD83D\\uDCDD', 'I', 'M', ';', 'q', 'D', 'W', '8', 'G', '6', 'L', 'H', ':', '7', 'O', \\\"'\\\", 'E', 'K', '9', 'U', 'N', 'V', 'J', '\\xAE', '\\xB0', '\\xE9', '\\\"', 'Y', 'Q', '*', '!', 'Z', '\\u2013', '&', '%', '\\xF1', '\\xE8', '\\u2122', '\\xEE', 'X', '?', '\\xBF', '\\u2014', '\\xE7', '#', '\\xBD', '\\xED', '=', '\\u2019', '\\xE2', '\\xA9', '\\xBC', '+', '>', '$', '<', '\\xE1', '\\xF3', '\\xFA', '\\xEF', '\\xC9', '\\xFB', ']', '[', '\\xFC', '\\xEA', '\\xE0', '_', '\\\\xad', '\\xBE', '\\u201A', '\\uFFFD', '\\xBA', '\\u2044', '\\xE4', '\\xDA', '\\xF9', '\\u0301', '}', '\\xF6', '{', '\\xEC', '\\xF4', '\\\\x96', '\\u201D', '\\xD7', '\\u02DA', '\\xBB', '@', '\\xA7', '\\\\\\\\', '\\u25CA', '\\u2031', '\\u201C', '\\u2027', '\\\\u202d', '\\u215B', '\\xE5', '\\uFB02', '`', '\\xC1', '\\xEB', '\\\\x97', '\\\\x1a', '\\xF8', '\\u2153', '|', '\\u01B0', '\\\\x92', '\\xB4', '\\u2012', '\\xC2', '\\u2423', '\\xA4', '\\u201F', '\\\\xa0', '\\u01A1', '\\u0103', '\\u0300', '\\u215E', '\\u20AC', '~', '\\\\x95']\")))), mdx(\"p\", null, \"These are all the characters our RNN model will work with. It will try to learn how to assemble these characters into sequences that will look like recipes.\"), mdx(\"p\", null, \"Let's see how we may use \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"tokenizer\"), \" functions to convert text to indices:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"texts_to_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\uD83D\\uDCD7 yes'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"[[51, 1, 28, 2, 9]]\")))), mdx(\"h2\", {\n    \"id\": \"vectorizing-the-dataset\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Vectorizing the dataset\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#vectorizing-the-dataset\",\n    \"aria-label\": \"vectorizing the dataset permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Now, once we have a vocabulary (\", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"character --> code\"), \" and \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"code --> character\"), \" relations) we may convert the set of recipes from text to numbers (RNN works with numbers as an input and not with the texts).\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset_vectorized \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"texts_to_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_filtered\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Vectorized dataset size'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Vectorized dataset size 100212\")))), mdx(\"p\", null, \"This is how the beginning of the first vectorized recipe looks like:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'...'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"[51, 1, 33, 10, 5, 23, 1, 35, 5, 5] ...\")))), mdx(\"p\", null, \"Let's see how can we convert vectorized recipe back to text representation:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"recipe_sequence_to_string\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_sequence\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    recipe_stringified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"recipe_sequence\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nrecipe_sequence_to_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7 Slow Cooker Chicken and Dumplings\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 4 skinless, boneless chicken breast halves\\n\\u2022 2 tablespoons butter\\n\\u2022 2 (10.75 ounce) cans condensed cream of chicken soup\\n\\u2022 1 onion, finely diced\\n\\u2022 2 (10 ounce) packages refrigerated biscuit dough, torn into pieces\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\n\\u25AA\\uFE0E Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\")))), mdx(\"h3\", {\n    \"id\": \"add-padding-to-sequences\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Add padding to sequences\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#add-padding-to-sequences\",\n    \"aria-label\": \"add padding to sequences permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"We need all recipes to have the same length for training. To do that we'll use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"\n  }, \"tf.keras.preprocessing.sequence.pad_sequences\"), \" utility to add a stop word to the end of each recipe and to make them have the same length.\"), mdx(\"p\", null, \"Let's check the recipes lengths:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"enumerate\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Recipe #{} length: {}'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_index \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Recipe #1 length: 546\\nRecipe #2 length: 401\\nRecipe #3 length: 671\\nRecipe #4 length: 736\\nRecipe #5 length: 1518\\nRecipe #6 length: 740\\nRecipe #7 length: 839\\nRecipe #8 length: 667\\nRecipe #9 length: 1264\\nRecipe #10 length: 854\")))), mdx(\"p\", null, \"Let's pad all recipes with a \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"STOP_SIGN\"), \":\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset_vectorized_padded_without_stops \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"preprocessing\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequence\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"pad_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    dataset_vectorized\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    padding\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'post'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    truncating\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'post'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# We use -1 here and +1 in the next step to make sure\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# that all recipes will have at least 1 stops sign at the end,\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# since each sequence will be shifted and truncated afterwards\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# (to generate X and Y sequences).\"), \"\\n    maxlen\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"MAX_RECIPE_LENGTH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    value\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"texts_to_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"STOP_SIGN\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\ndataset_vectorized_padded \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"preprocessing\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequence\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"pad_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    dataset_vectorized_padded_without_stops\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    padding\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'post'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    truncating\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'post'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    maxlen\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"MAX_RECIPE_LENGTH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    value\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"texts_to_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"STOP_SIGN\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"enumerate\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized_padded\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Recipe #{} length: {}'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe_index\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Recipe #0 length: 2001\\nRecipe #1 length: 2001\\nRecipe #2 length: 2001\\nRecipe #3 length: 2001\\nRecipe #4 length: 2001\\nRecipe #5 length: 2001\\nRecipe #6 length: 2001\\nRecipe #7 length: 2001\\nRecipe #8 length: 2001\\nRecipe #9 length: 2001\")))), mdx(\"p\", null, \"After the padding all recipes in the dataset now have the same length and RNN will also be able to learn where each recipe stops (by observing the presence of a \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"STOP_SIGN\"), \").\"), mdx(\"p\", null, \"Here is an example of how a first recipe looks like after the padding.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"recipe_sequence_to_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized_padded\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7 Slow Cooker Chicken and Dumplings\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 4 skinless, boneless chicken breast halves\\n\\u2022 2 tablespoons butter\\n\\u2022 2 (10.75 ounce) cans condensed cream of chicken soup\\n\\u2022 1 onion, finely diced\\n\\u2022 2 (10 ounce) packages refrigerated biscuit dough, torn into pieces\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\n\\u25AA\\uFE0E Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\")))), mdx(\"p\", null, \"All recipes now end with one or many \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"\\u2423\"), \" signs. We expect our LSTM model to learn that whenever it sees the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"\\u2423\"), \" stop-character it means that the recipe is ended. Once the network will learn this concept it will put stop-character at the end of every newly generated recipe.\"), mdx(\"h3\", {\n    \"id\": \"create-tensorflow-dataset\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Create TensorFlow dataset\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#create-tensorflow-dataset\",\n    \"aria-label\": \"create tensorflow dataset permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Up until now we were working with the dataset as with the NumPy array. It will be more convenient during the training process if we will convert a dataset NumPy array to a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\"\n  }, \"TensorFlow dataset\"), \". It will give us an ability to use such helpers functions as \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"batch()\"), \", \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"shuffle()\"), \", \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"repeat()\"), \", \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"prefecth()\"), \" etc.:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"dataset \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"data\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Dataset\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"from_tensor_slices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_vectorized_padded\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"<TensorSliceDataset shapes: (2001,), types: tf.int32>\")))), mdx(\"p\", null, \"Let's see what the first recipe in the dataset looks like by using a TensorFlow dataset API this time:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" recipe \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"take\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Raw recipe:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n\\\\n\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Stringified recipe:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    recipe_sequence_to_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Raw recipe:\\n [ 51   1  33 ... 165 165 165]\\n\\nStringified recipe:\\n\\n\\uD83D\\uDCD7 Slow Cooker Chicken and Dumplings\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 4 skinless, boneless chicken breast halves\\n\\u2022 2 tablespoons butter\\n\\u2022 2 (10.75 ounce) cans condensed cream of chicken soup\\n\\u2022 1 onion, finely diced\\n\\u2022 2 (10 ounce) packages refrigerated biscuit dough, torn into pieces\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\n\\u25AA\\uFE0E Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\")))), mdx(\"h3\", {\n    \"id\": \"split-examples-on-input-and-target-texts\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Split examples on \", mdx(\"code\", {\n    parentName: \"h3\",\n    \"className\": \"language-text\"\n  }, \"input\"), \" and \", mdx(\"code\", {\n    parentName: \"h3\",\n    \"className\": \"language-text\"\n  }, \"target\"), \" texts\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#split-examples-on-input-and-target-texts\",\n    \"aria-label\": \"split examples on input and target texts permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"For each sequence we need to duplicate and shift it to form the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"input\"), \" and \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"target\"), \" texts. For example, say the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"sequence_length\"), \" is \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"4\"), \" and our text is \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"Hello\"), \". The input sequence would be \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"Hell\"), \", and the target sequence \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"ello\"), \".\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"split_input_target\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    input_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    target_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" input_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_text\\n\\ndataset_targeted \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" dataset\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"map\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"split_input_target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_targeted\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"<MapDataset shapes: ((2000,), (2000,)), types: (tf.int32, tf.int32)>\")))), mdx(\"p\", null, \"You may notice from the line above, that now each example in the dataset consists of two tuples: input and target. Let's print an example:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" input_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_example \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_targeted\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"take\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Input sequence size:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Target sequence size:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"len\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    input_stringified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"input_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    target_stringified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"target_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Input:  '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Target: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target_stringified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Input sequence size: 2000\\nTarget sequence size: 2000\\n\\nInput:   '\\uD83D\\uDCD7   S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \\\\n \\\\n \\uD83E\\uDD55 \\\\n \\\\n \\u2022   4   s k i n l e'\\nTarget:  '  S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \\\\n \\\\n \\uD83E\\uDD55 \\\\n \\\\n \\u2022   4   s k i n l e s'\")))), mdx(\"p\", null, \"Each index of these vectors is processed as one time step by RNN. For the input at time step \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"0\"), \", the model receives the index for \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"\\uD83D\\uDCD7\"), \" and tries to predict the index for \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \" \"), \" (a space character) as the next character. At the next time-step, it does the same thing, but the RNN considers the previous step context in addition to the current input character.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" i\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"enumerate\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"zip\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_example\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Step {:2d}'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"i \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'  input: {} ({:s})'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"input_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'  expected output: {} ({:s})'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"format\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"target_idx\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Step  1\\n  input: 51 ('\\uD83D\\uDCD7')\\n  expected output: 1 (' ')\\nStep  2\\n  input: 1 (' ')\\n  expected output: 33 ('S')\\nStep  3\\n  input: 33 ('S')\\n  expected output: 10 ('l')\\nStep  4\\n  input: 10 ('l')\\n  expected output: 5 ('o')\\nStep  5\\n  input: 5 ('o')\\n  expected output: 23 ('w')\\nStep  6\\n  input: 23 ('w')\\n  expected output: 1 (' ')\\nStep  7\\n  input: 1 (' ')\\n  expected output: 35 ('C')\\nStep  8\\n  input: 35 ('C')\\n  expected output: 5 ('o')\\nStep  9\\n  input: 5 ('o')\\n  expected output: 5 ('o')\\nStep 10\\n  input: 5 ('o')\\n  expected output: 25 ('k')\")))), mdx(\"h3\", {\n    \"id\": \"split-up-the-dataset-into-batches\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Split up the dataset into batches\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#split-up-the-dataset-into-batches\",\n    \"aria-label\": \"split up the dataset into batches permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"We have \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"~100k\"), \" recipes in the dataset, and each recipe has two tuples of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2000\"), \" characters.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_targeted\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"<MapDataset shapes: ((2000,), (2000,)), types: (tf.int32, tf.int32)>\")))), mdx(\"p\", null, \"Let's print constants values:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'TOTAL_RECIPES_NUM: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" TOTAL_RECIPES_NUM\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'MAX_RECIPE_LENGTH: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" MAX_RECIPE_LENGTH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'VOCABULARY_SIZE: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" VOCABULARY_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"TOTAL_RECIPES_NUM:  100212\\nMAX_RECIPE_LENGTH:  2000\\nVOCABULARY_SIZE:  176\")))), mdx(\"p\", null, \"If we will feed the complete dataset during the training process to the model and then will try to do a back-propagation for all examples at once we might run out of memory and each training epoch may take too long to execute. To avoid the situation like this we need to split our dataset into batches.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Batch size.\"), \"\\nBATCH_SIZE \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"64\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Buffer size to shuffle the dataset (TF data is designed to work\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# with possibly infinite sequences, so it doesn't attempt to shuffle\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# the entire sequence in memory. Instead, it maintains a buffer in\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# which it shuffles elements).\"), \"\\nSHUFFLE_BUFFER_SIZE \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1000\"), \"\\n\\ndataset_train \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" dataset_targeted \\\\\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Shuffling examples first.\"), \"\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shuffle\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"SHUFFLE_BUFFER_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \\\\\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Splitting examples on batches.\"), \"\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"batch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"BATCH_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" drop_remainder\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \\\\\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Making a dataset to be repeatable (it will never ends).\"), \"\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"repeat\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"dataset_train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"<RepeatDataset shapes: ((64, 2000), (64, 2000)), types: (tf.int32, tf.int32)>\")))), mdx(\"p\", null, \"From the line above you may notice that our dataset now consists of the same two tuples of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2000\"), \" characters but now they are grouped in the batches by \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"64\"), \".\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" input_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"take\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'1st batch: input_text:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" input_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'1st batch: target_text:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"1st batch: input_text: tf.Tensor(\\n[[ 51   1  54 ... 165 165 165]\\n [ 51   1  64 ... 165 165 165]\\n [ 51   1  44 ... 165 165 165]\\n ...\\n [ 51   1  69 ... 165 165 165]\\n [ 51   1  55 ... 165 165 165]\\n [ 51   1  70 ... 165 165 165]], shape=(64, 2000), dtype=int32)\\n\\n1st batch: target_text: tf.Tensor(\\n[[  1  54   4 ... 165 165 165]\\n [  1  64   5 ... 165 165 165]\\n [  1  44   6 ... 165 165 165]\\n ...\\n [  1  69   3 ... 165 165 165]\\n [  1  55   3 ... 165 165 165]\\n [  1  70   2 ... 165 165 165]], shape=(64, 2000), dtype=int32)\")))), mdx(\"h2\", {\n    \"id\": \"build-the-model\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Build the model\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#build-the-model\",\n    \"aria-label\": \"build the model permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"We will use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\"\n  }, \"tf.keras.Sequential\"), \" to define the model. For this experiment we will use the following layer types:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\"\n  }, \"tf.keras.layers.Embedding\"), \" - the input layer (a trainable lookup table that will map the numbers of each character to a vector with \", mdx(\"code\", {\n    parentName: \"li\",\n    \"className\": \"language-text\"\n  }, \"embedding_dim\"), \" dimensions),\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\"\n  }, \"tf.keras.layers.LSTM\"), \" - a type of RNN with size \", mdx(\"code\", {\n    parentName: \"li\",\n    \"className\": \"language-text\"\n  }, \"units=rnn_units\"), \" (you can also use a \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\"\n  }, \"GRU\"), \" layer here),\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\"\n  }, \"tf.keras.layers.Dense\"), \" - the output layer, with \", mdx(\"code\", {\n    parentName: \"li\",\n    \"className\": \"language-text\"\n  }, \"VOCABULARY_SIZE\"), \" outputs.\")), mdx(\"h3\", {\n    \"id\": \"figuring-out-how-the-embedding-layer-works\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Figuring out how the Embedding Layer works\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#figuring-out-how-the-embedding-layer-works\",\n    \"aria-label\": \"figuring out how the embedding layer works permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's do a quick detour and see how Embedding Layer works. It takes several char indices sequences (batch) as an input. It encodes every character of every sequence to a vector of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"tmp_embedding_size\"), \" length.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"tmp_vocab_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), \"\\ntmp_embedding_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"5\"), \"\\ntmp_input_length \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"8\"), \"\\ntmp_batch_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \"\\n\\ntmp_model \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"models\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Sequential\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\ntmp_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"add\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"layers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Embedding\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n  input_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tmp_vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  output_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tmp_embedding_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  input_length\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tmp_input_length\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# The model will take as input an integer matrix of size (batch, input_length).\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\"), \"\\ntmp_input_array \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"randint\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n  low\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  high\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tmp_vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tmp_batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" tmp_input_length\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\ntmp_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"compile\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'rmsprop'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'mse'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\ntmp_output_array \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tmp_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"predict\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tmp_input_array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'tmp_input_array shape:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" tmp_input_array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'tmp_input_array:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tmp_input_array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'tmp_output_array shape:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" tmp_output_array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'tmp_output_array:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tmp_output_array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"tmp_input_array shape: (2, 8)\\ntmp_input_array:\\n[[2 4 7 5 1 6 9 7]\\n [3 6 8 1 4 0 1 2]]\\n\\ntmp_output_array shape: (2, 8, 5)\\ntmp_output_array:\\n[[[-0.02229502 -0.02800617 -0.0120693  -0.01681594 -0.00650246]\\n  [-0.03046973 -0.03920818  0.04956308  0.04417323 -0.00446874]\\n  [-0.0215276   0.01532575 -0.02229529  0.02834387  0.02725342]\\n  [ 0.04567988  0.0141306   0.00877035 -0.02601192  0.00380837]\\n  [ 0.02969306  0.02994296 -0.00233263  0.00716375 -0.00847433]\\n  [ 0.04598364 -0.00704358 -0.01386416  0.01195388 -0.00309662]\\n  [-0.00137572  0.01275543 -0.02348721 -0.04825885  0.00527108]\\n  [-0.0215276   0.01532575 -0.02229529  0.02834387  0.02725342]]\\n\\n [[ 0.01082945  0.03824175 -0.00450991 -0.02865709  0.02502238]\\n  [ 0.04598364 -0.00704358 -0.01386416  0.01195388 -0.00309662]\\n  [ 0.02275398  0.03806095 -0.03491788  0.04705564  0.00167596]\\n  [ 0.02969306  0.02994296 -0.00233263  0.00716375 -0.00847433]\\n  [-0.03046973 -0.03920818  0.04956308  0.04417323 -0.00446874]\\n  [-0.02909902  0.04426369  0.00150937  0.04579213  0.02559013]\\n  [ 0.02969306  0.02994296 -0.00233263  0.00716375 -0.00847433]\\n  [-0.02229502 -0.02800617 -0.0120693  -0.01681594 -0.00650246]]]\")))), mdx(\"h3\", {\n    \"id\": \"lstm-model\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"LSTM Model\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#lstm-model\",\n    \"aria-label\": \"lstm model permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's assemble the model.\"), mdx(\"p\", null, \"\\u2139\\uFE0F You may check \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/tutorials/text/text_generation\"\n  }, \"Text generation with an RNN\"), \" notebook from TensorFlow documentation for more details on model components.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"build_model\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" embedding_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" rnn_units\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    model \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"models\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Sequential\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"add\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"layers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Embedding\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n        input_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        output_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"embedding_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        batch_input_shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"None\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"add\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"layers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"LSTM\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n        units\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"rnn_units\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        return_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        stateful\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        recurrent_initializer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"initializers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"GlorotNormal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"add\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"layers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Dense\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" model\\n\\nmodel \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" build_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n  vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"VOCABULARY_SIZE\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  embedding_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"256\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  rnn_units\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1024\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n  batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"BATCH_SIZE\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nmodel\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"summary\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Model: \\\"sequential_13\\\"\\n_________________________________________________________________\\nLayer (type)                 Output Shape              Param #\\n=================================================================\\nembedding_13 (Embedding)     (64, None, 256)           45056\\n_________________________________________________________________\\nlstm_9 (LSTM)                (64, None, 1024)          5246976\\n_________________________________________________________________\\ndense_8 (Dense)              (64, None, 176)           180400\\n=================================================================\\nTotal params: 5,472,432\\nTrainable params: 5,472,432\\nNon-trainable params: 0\\n_________________________________________________________________\")))), mdx(\"p\", null, \"Let's visualize the model:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"utils\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"plot_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    show_shapes\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    show_layer_names\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    to_file\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'model.png'\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"439px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"89.99999999999999%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACQklEQVQ4y2WUhw4iMQxE9/8/CwmEKKL33nsH0UJyftYZ7R0rmTi79sSecYjW67W73W7ucrmomX+9XtXMt3W5XLpOp+MqlYrbbreu0Wi4Wq3mBoOB6/f7LprP56HVagUJCKVSKcxms7DZbIIkqQ2Hw1Aul0O73Q6SEARQYzOZjPp8KxaL+g2caLFY+N1u5wXES7VegnSPj+ETw3upyE+nUy+AXgD9ZDLxUqEXUC8V+l6v56P3+x3MnHNq5tsq7Yb7/a7+8/kMn88neO+/eewtN2JDEPZ6vf7xH49H4KF1WgIE4xsHsJJvsQq43+/D4XAIp9Mp4J/PZ/Wl1e/71WqlNhqNQj6fV3BpX9/BodCgsVjEj/SuxGL1el2DSapWq2qACF9BeAqpVErJZ8/a7Xa1A0QjTwGPx6PyhFllMiJaLe/4LgJpUi6XU6DxeKzVoXSz2VTltUI4oH/jDpLjXMKLUWFimGDGn4nCGoW/j33E4ioDACW0iG/k/z8J9kQE8dA/Rtm0TSsMPSY3QVuVedRBh2sOYIUGOrAJ0Apx4Aku4AZlEUeGVkEAzGazqjLv2HOjEAvRuFmG862QyuDJhEAUudcqBkmFQkEPs5nkIA5FIIr5ATR+TAx8DG5J4ID4jTB+TagfwPhNMXFMZaqiOpLthsQPZv8DyNTDhYlCq/is8JZIJFQQeIZPRIHDdDqt/g8gqkK2VcOowBEqsyaTSVWUa4a6CEQ8A00xP4BUBVcYKpsRzPXiv9L+D9lzEEpzHRkbA/wDgrNJaGCv1EMAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Model architecture\",\n    \"title\": \"Model architecture\",\n    \"src\": \"/static/69dd454b38a2cb834ff2399587d6cd92/e3b18/4.png\",\n    \"srcSet\": [\"/static/69dd454b38a2cb834ff2399587d6cd92/63868/4.png 250w\", \"/static/69dd454b38a2cb834ff2399587d6cd92/e3b18/4.png 439w\"],\n    \"sizes\": \"(max-width: 439px) 100vw, 439px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"For each character the model looks up the embedding, runs the LSTM one time-step with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"842px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"86.80000000000001%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEhklEQVQ4y21Ue0xTZxT/Cm1veRgeEkAXGdk6x8xgPJQx0jEwTuaYvHRMUAq28ggKFCgMyqNQYeXZUiilD0pboTzaUkrpi6cWygwCizCREdHslc3NmWxmfyzT5O7eAlk6d5JfvnPPOff3ne87v3sBDMMYBODe8qjgK5vyyf0V9eakikv9Zm1sdXVh8PHmHbUc7BoOyelWrDce76zrNsjpCW8jsYMEAuSPrPvAABh+DlBCg4Yfwm0uy1VKmxKFndUBE8Mtn0n5lTSrSRCNFDohcDaN9URy2aU5Q/1fnM3PyYQUfe3gA9IJ4GAoGYpHtxtl1rHSnzZmazbWLIy6e/O12/Mq2rMHSywDSki5QIKQmqmZ4aLvH9hYmxZl0bE1SzVQ8qlO/0u4ZaGRxE3nynVCctaqKvt1XW/GR7VXYylbpoJQtDsIA7D3LbR4fn0SfUpGIa8MpbsWX4oAL9mjZw8xCZ/E4fQ2g7RbIVgemVLNqWfUXaoZjblXKbo9uWQYDj1+DFfXUuOis+oneTL+kvamztrIa4xHXj/wRhDRH4fD+aK+nVA6KgIr218Ck3WCxpWyhcqJ/natZbR4xKDgcPrYMiTOPOIXCFHys1wn57SsDkkTX2Ue7BLJBMF/w3/YT4cY1sfXB2/3edIOmkwjYZ7NPRnC0dYrmwYqS9BEtaSQ3KGpl5/MC3sVpAKnVes6IDckhnO1LGOV8Goyeg3ikR66ckLOHDUr/ZPTEneP3NzdOMTr65grac1LERrbv+vWNQ+i4+doWEKxiftnpbggDnnGo7WsAfo5kYHzF0fNYoBA4NIuap5uE7A3y+tKUCUQ/A/7u4EBnQwYrToAl8BOR32IQTFEkh/aYer7SYei3jkepi5VQclV7wEQDEA6yMfiAZ5IdCd6e535d6CIuUIQ5IWsLuCHb7ed0eC8Sj88OzIBL2rNT250Cmm2ccuPs8M6+JbaYNgXNpKzzo7oXqwY53/OTst4F4l5BwQcOYzFYl9BfD8EHmD75h37LtIuwdFc8uXMmrKK09zWNp+Gz6tPXcnMIkt4PW+h9+Xh6YkVcboirmRmU69X1SbUVDGgIZkChIaEOMrGptADeRsfdF6rI9WSCy+25lclCUobo9g5FYkNl0sudhc3xKEbPrc+xDRR6dEVF/ISG7JpH/KKmF6dhXWAnVvhSHg+9gy6OBk65L9pmyXwRFs/PMYW7xg5CljDFsP6NtmL+MgYAiPrmoe5c8Cen+Ip4QEm71NdSx/oLrvu7EAYfYkMgKcrZry85bWMyLjTdUnkE2pGRyArlRKRFhETr6U3E50gCBfxZjBeXlgfnhpOSmGep8bNtcndT4VFvfyl7E+qz3ArVjQ2VS4zWqnMXkWQwryYKxmfqZaZFhJ+2Z0kWpMiGptmyM2L+aSPk9AhHMATCG7/JbT/vkbNS0L9wt2nk4vrW1zJcI7eencd8Z9qZpZRXTrj8RCkmV7WI/FfjbavtygFpcGoTDy9D7o7EBbQa8DO7/YODiHwQeC1B7c9Kfji8HgXVCJ78ESAygRn1xIe78D3Dx8+ExWO24C9AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Model architecture\",\n    \"title\": \"Model architecture\",\n    \"src\": \"/static/c47fb3afb041ecd74a969c20df71db1c/99072/5.png\",\n    \"srcSet\": [\"/static/c47fb3afb041ecd74a969c20df71db1c/63868/5.png 250w\", \"/static/c47fb3afb041ecd74a969c20df71db1c/0b533/5.png 500w\", \"/static/c47fb3afb041ecd74a969c20df71db1c/99072/5.png 842w\"],\n    \"sizes\": \"(max-width: 842px) 100vw, 842px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Image source: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/tutorials/text/text_generation\"\n  }, \"Text generation with an RNN\"), \" notebook.\")), mdx(\"p\", null, \"The picture above illustrates GRU network, but you may easily replace GRU with LSTM.\"), mdx(\"h2\", {\n    \"id\": \"trying-the-model-before-training\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Trying the model before training\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#trying-the-model-before-training\",\n    \"aria-label\": \"trying the model before training permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's play around with un-trained model to see its interface (what input do we need and what output will we have) and let's see what model predicts before the training:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" input_example_batch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target_example_batch \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" dataset_train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"take\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    example_batch_predictions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_example_batch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"example_batch_predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"\\\"# (batch_size, sequence_length, vocab_size)\\\"\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"(64, 2000, 176) # (batch_size, sequence_length, vocab_size)\")))), mdx(\"p\", null, \"To get actual predictions from the model we need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Prediction for the 1st letter of the batch 1st sequense:'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"example_batch_predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Prediction for the 1st letter of the batch 1st sequense:\\ntf.Tensor(\\n[-9.0643829e-03 -1.9503604e-03  9.3381782e-04  3.7442446e-03\\n -2.0541784e-03 -7.4054599e-03 -7.1884273e-03  2.6014952e-03\\n  4.8721582e-03  3.0045470e-04  2.6016519e-04 -4.1374690e-03\\n  5.3856964e-03  2.6284808e-03 -5.6002503e-03  2.6019611e-03\\n -1.9491187e-03 -3.1097094e-04  6.3465843e-03  1.4640498e-03\\n  2.4560774e-03 -3.1256995e-03  1.4104056e-03  2.5478401e-04\\n  5.4266443e-03 -4.1188141e-03  3.6904984e-03 -5.8337618e-03\\n  3.6372752e-03 -3.1899021e-05  3.2178329e-03  1.5033322e-04\\n  5.2770867e-04 -8.1920059e-04 -2.2364906e-03 -2.3271297e-03\\n  4.4109682e-03  4.2381673e-04  1.0532180e-03 -1.4208974e-03\\n -3.2446394e-03 -4.5869066e-03  4.3250201e-04 -4.3490473e-03\\n  3.7889536e-03 -9.2122913e-04  7.8936084e-04 -9.7079907e-04\\n  1.7070504e-03 -2.5260956e-03  6.7904620e-03  1.5470090e-03\\n -9.4337866e-04 -1.5072266e-03  6.8939931e-04 -1.0795534e-03\\n -3.1912089e-03  2.3665284e-03  1.7737487e-03 -2.3504677e-03\\n -6.8649277e-04  9.6421910e-04 -4.1204207e-03 -3.8750230e-03\\n  1.9077851e-03  4.7145790e-05 -2.9846188e-03  5.8050319e-03\\n -5.6210475e-04 -2.5910907e-04  5.2890396e-03 -5.8653783e-03\\n -6.0040038e-06  2.3905798e-03 -2.9405006e-03  2.0132761e-03\\n -3.5594390e-03  4.0282350e-04  4.7719614e-03 -2.4438011e-03\\n -1.1028582e-03  2.0007135e-03 -1.6961874e-03 -4.2196750e-03\\n -3.5689408e-03 -4.1934610e-03 -8.5307617e-04  1.5773368e-04\\n -1.4612130e-03  9.5826073e-04  4.0543079e-04 -2.3562380e-04\\n -1.5394683e-03  3.6650903e-03  3.5997448e-03  2.2390878e-03\\n -6.8982318e-04  1.4068574e-03 -2.0531749e-03 -1.5443334e-03\\n -1.8235333e-03 -3.2099178e-03  1.6660831e-03  1.2230751e-03\\n  3.8084832e-03  6.9559496e-03  5.7684043e-03  3.1751506e-03\\n  7.4234616e-04  1.1971325e-04 -2.7798198e-03  2.1485630e-03\\n  4.0362971e-03  6.4410735e-05  1.7432809e-03  3.2334479e-03\\n -6.1469898e-03 -2.2205685e-03 -1.0864032e-03 -2.0876178e-07\\n  2.3065242e-03 -1.5816523e-03 -2.1492387e-03 -4.4033155e-03\\n  1.1003019e-03 -9.7132073e-04 -6.3941808e-04  3.0277157e-03\\n  2.9096641e-03 -2.4778468e-03 -2.9532036e-03  7.7463314e-04\\n  2.7473709e-03 -7.6333171e-04 -8.1811845e-03 -1.3959130e-03\\n  3.2840301e-03  6.0461317e-03 -1.3022404e-04 -9.4000692e-04\\n -2.0096730e-04  3.3895797e-03  2.9710699e-03  1.9046264e-03\\n  2.5092331e-03 -2.0799250e-04 -2.2211851e-04 -3.4621451e-05\\n  1.9962704e-03 -2.3159904e-03  2.9832027e-03  3.3852295e-03\\n  3.4411502e-04 -1.9019389e-03 -3.6734296e-04 -1.4232489e-03\\n  2.6938838e-03 -2.8015859e-03 -5.7366290e-03  8.0239226e-04\\n -6.2909431e-04  1.1508183e-03 -1.5899434e-04 -5.9326587e-04\\n -4.1618512e-04  5.2454891e-03  1.2823739e-03 -1.7550631e-03\\n -3.0120560e-03 -3.8433261e-03 -9.6873334e-04  1.9963509e-03\\n  1.8154597e-03  4.7434499e-03  1.7146189e-03  1.1544267e-03], shape=(176,), dtype=float32)\")))), mdx(\"p\", null, \"For each input character the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"example_batch_predictions\"), \" array contains a vector of probabilities of what the next character might be. If probability at position \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"15\"), \" in that vector is, lets say, \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"0.3\"), \" and the probability at position \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"25\"), \" is \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"1.1\"), \" it means that we should better pick the character with the index \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"25\"), \" as next following character.\"), mdx(\"p\", null, \"Since we want our network to generate different recipes (even for the same input), we can't just pick the maximum probability value. In this case we will end up with the same recipe being predicted by the network over and over again. What we will do instead is drawing \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"samples\"), \" from predictions (like the one printed above) by using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/random/categorical\"\n  }, \"tf.random.categorical()\"), \" function. It will bring some fuzziness to the network. For example, let's say we have character \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"H\"), \" as an input, then, by sampling from categorical distribution, our network may predict not only the word \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"He\"), \", but also words \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"Hello\"), \", and \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"Hi\"), \" etc.\"), mdx(\"h3\", {\n    \"id\": \"understanding-how-tfrandomcategorical-works\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Understanding how \", mdx(\"code\", {\n    parentName: \"h3\",\n    \"className\": \"language-text\"\n  }, \"tf.random.categorical\"), \" works\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#understanding-how-tfrandomcategorical-works\",\n    \"aria-label\": \"understanding how tfrandomcategorical works permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# logits is 2-D Tensor with shape [batch_size, num_classes].\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# In the example below we say that the probability for class \\\"0\\\"\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# (element with index 0) is low but the probability for class \\\"2\\\" is much higher.\"), \"\\ntmp_logits \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"\\n  \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.95\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.95\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \";\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Let's generate 5 samples. Each sample is a class index. Class probabilities\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# are being taken into account (we expect to see more samples of class \\\"2\\\").\"), \"\\ntmp_samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"categorical\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tmp_logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    num_samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"5\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tmp_samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"tf.Tensor([[2 1 2 2 1]], shape=(1, 5), dtype=int64)\")))), mdx(\"h3\", {\n    \"id\": \"sampling-from-lstm-predictions\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Sampling from LSTM predictions\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#sampling-from-lstm-predictions\",\n    \"aria-label\": \"sampling from lstm predictions permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"sampled_indices \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"categorical\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"example_batch_predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    num_samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nsampled_indices \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"squeeze\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"input\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"sampled_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    axis\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nsampled_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"(2000,)\")))), mdx(\"p\", null, \"Let's see some sampled predictions for the first \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"100\"), \" chars of the recipe:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"sampled_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"100\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"array([ 64,  21,  91, 126, 170,  42, 146,  54, 125, 164,  60, 171,   9,\\n        87, 129,  28, 146, 103,  41, 101, 147,   3, 134, 171,   8, 170,\\n       105,   5,  44, 173,   5, 105,  17, 138, 165,  32,  88,  96, 145,\\n        83,  33,  65, 172, 162,   8,  29, 147,  58,  81, 153, 150,  56,\\n       156,  38, 144, 134,  13,  40,  17,  50,  27,  35,  39, 112,  63,\\n       139, 151, 133,  68,  29,  91,   2,  70, 112, 135,  31,  26, 156,\\n       118,  71,  49, 104,  75,  27, 164,  41, 117, 124,  18, 137,  59,\\n       160, 158, 119, 173,  50,  78,  45, 121, 118])\")))), mdx(\"p\", null, \"We may see now what our untrained model actually predicts:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Input:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"input_example_batch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Next char prediction:\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"repr\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"sampled_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Input:\\n '\\uD83D\\uDCD7   R e s t a u r a n t - S t y l e   C o l e s l a w   I \\\\n \\\\n \\uD83E\\uDD55 \\\\n \\\\n \\u2022   1   ( 1 6   o u n c e )   p'\\n\\nNext char prediction:\\n 'H . \\xEE \\u2044 \\u0103 ( \\u201C I \\xBA \\xC2 8 \\u0300 s % \\xF9 y \\u201C \\xA9 0 \\u2019 \\u2027 a \\xEC \\u0300 r \\u0103 + o A \\u20AC o + m \\xD7 \\u2423 \\uFE0E \\xF1 \\xE7 \\u2031 ! S : \\u215E \\xB4 r 2 \\u2027 D Q \\xC1'\")))), mdx(\"p\", null, \"As you may see, the model suggests some meaningless predictions, but this is because it wasn't trained yet.\"), mdx(\"h2\", {\n    \"id\": \"training-the-model\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Training the model\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#training-the-model\",\n    \"aria-label\": \"training the model permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"We want to train our model to generate recipes as similar to the real ones as possible. We will use all data from dataset for training. There is not need to extract test or validation sub-sets in this case.\"), mdx(\"h3\", {\n    \"id\": \"attach-an-optimizer-and-a-loss-function\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Attach an optimizer, and a loss function\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#attach-an-optimizer-and-a-loss-function\",\n    \"aria-label\": \"attach an optimizer and a loss function permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"We're going to use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\"\n  }, \"tf.keras.optimizers.Adam\"), \" optimizer with \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy\"\n  }, \"tf.keras.losses.sparse_categorical_crossentropy()\"), \" loss function to train the model:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# An objective function.\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"loss\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"labels\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    entropy \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"losses\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sparse_categorical_crossentropy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n      y_true\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"labels\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n      y_pred\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n      from_logits\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" entropy\\n\\nexample_batch_loss \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" loss\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target_example_batch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" example_batch_predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"\\\"Prediction shape: \\\"\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" example_batch_predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"\\\" # (batch_size, sequence_length, vocab_size)\\\"\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"\\\"scalar_loss.shape:      \\\"\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" example_batch_loss\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"\\\"scalar_loss:      \\\"\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" example_batch_loss\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"mean\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Prediction shape:    (64, 2000, 176)  # (batch_size, sequence_length, vocab_size)\\nscalar_loss.shape:   (64, 2000)\\nscalar_loss:         5.1618285\")))), mdx(\"p\", null, \"Let's finally compile the model:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"adam_optimizer \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"optimizers\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"Adam\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"learning_rate\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.001\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nmodel\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"compile\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    optimizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"adam_optimizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    loss\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"loss\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"h3\", {\n    \"id\": \"configuring-callbacks\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Configuring callbacks\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#configuring-callbacks\",\n    \"aria-label\": \"configuring callbacks permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"h4\", {\n    \"id\": \"early-stopping-callback\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Early stopping callback\", mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#early-stopping-callback\",\n    \"aria-label\": \"early stopping callback permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"For model training process we may configure a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\"\n  }, \"tf.keras.callbacks.EarlyStopping\"), \" callback. It will stop the training automatically in case if model is not improving for several epochs anymore:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"early_stopping_callback \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"callbacks\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"EarlyStopping\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    patience\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"5\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    monitor\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'loss'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    restore_best_weights\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    verbose\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"h4\", {\n    \"id\": \"model-checkpoints-callback\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Model checkpoints callback\", mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#model-checkpoints-callback\",\n    \"aria-label\": \"model checkpoints callback permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's also configure a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\"\n  }, \"tf.keras.callbacks.ModelCheckpoint\"), \" checkpoint that will allow us to periodically save trained weights to the file so that we could restore the model from weights afterwards.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Create a checkpoints directory.\"), \"\\ncheckpoint_dir \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'tmp/checkpoints'\"), \"\\nos\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"makedirs\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"checkpoint_dir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" exist_ok\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\ncheckpoint_prefix \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" os\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"path\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"checkpoint_dir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'ckpt_{epoch}'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\ncheckpoint_callback\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"keras\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"callbacks\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"ModelCheckpoint\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    filepath\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"checkpoint_prefix\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    save_weights_only\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"True\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"h3\", {\n    \"id\": \"execute-the-training\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Execute the training\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#execute-the-training\",\n    \"aria-label\": \"execute the training permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Let's train our model for \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"500\"), \" epochs with \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"1500\"), \" steps per each epoch. For each epoch step the batch of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"64\"), \" recipes will be fetched and gradient descent will be executed for those \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"64\"), \" recipes of length \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"2000\"), \" step by step.\"), mdx(\"p\", null, \"If you're experimenting with training parameters it might make sense to reduce the number of epochs to, let's say \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"20\"), \" along with the number of steps per epoch and then see how the model performs under that conditions. If the model improves its performance you may add more data (steps and epochs) to the training process. It might save you some time while you adjust parameters.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"EPOCHS \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"500\"), \"\\nINITIAL_EPOCH \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\nSTEPS_PER_EPOCH \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1500\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'EPOCHS:          '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" EPOCHS\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'INITIAL_EPOCH:   '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" INITIAL_EPOCH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'STEPS_PER_EPOCH: '\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" STEPS_PER_EPOCH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"EPOCHS:           500\\nINITIAL_EPOCH:    1\\nSTEPS_PER_EPOCH:  1500\")))), mdx(\"p\", null, \"Let's launch the training:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"history \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"fit\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"dataset_train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    epochs\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"EPOCHS\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    steps_per_epoch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"STEPS_PER_EPOCH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    initial_epoch\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"INITIAL_EPOCH\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    callbacks\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"\\n        checkpoint_callback\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n        early_stopping_callback\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Saving the trained model to file (to be able to re-use it later).\"), \"\\nmodel_name \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'recipe_generation_rnn_raw.h5'\"), \"\\nmodel\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"save\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"model_name\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" save_format\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'h5'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"h3\", {\n    \"id\": \"visualizing-training-progress\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Visualizing training progress\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#visualizing-training-progress\",\n    \"aria-label\": \"visualizing training progress permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"render_training_history\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"training_history\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    loss \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" training_history\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"history\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'loss'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"title\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Loss'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"xlabel\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Epoch'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"ylabel\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Loss'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"plot\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"loss\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" label\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Training set'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"legend\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"grid\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"linestyle\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'--'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" linewidth\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.5\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    plt\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"show\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nrender_training_history\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"history\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"392px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"70.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACqklEQVQ4y5VUS28SURS+aevKNq5KujAm7jVpSpVEksb4Q0qM8Xe4dAcNlNQfQI0L60YFig31QSUlLASVxyRQCW8Z2gGGmTuvez1nGFowceFNvpxzZ8585zvn3DuEc06ePnlMYu/fLX/9fLyW+HDkOjq6QiKRcKXT6VWfz3dne3v77unp6So++3ScdKW/fHTlcjlXqVRyFQqFtVgstkLi8cNFJK3+qj3rD2SZUrWuKEoLoapqa+oD2rIsd/AZBfSlYavdu2hVq9WWIAj1SqUyBvuchEK71wghS/V6PXQx1rjFGGcOcP3tT5dumFwDQCI+HA75aDTi3W73BQmHw0i40Gk1AhIQjqmuM8uyTNO0LMfO+tOFPiSwgButhslEUdwlkUhkCUvudjp+zHguawYqgHhbCXx7qfIfPgNyA/dAGCZ+vx8VLjYajQAG9IaqoeoGx+RYPgRffjz1Eeg7xPOEN2EBIWk2m34MgN4YHUnhiqZj17jxv4Rer3cFewiEActuOrNfdgeKMwQ2RzgtecbHll8RQqmLzpR3nIxYL5epzsUR5QNFm/TT6dusQhCHmFe4v79vDwV76ARDlSZkNdmYGmwwpgz6iiqYqumoByUBTGZnmUjEkzEhDAaD9lCg5B3niBmzZw+XAoMXR5qjWLffDVWdn8MxQ4xginhC+v1+mOzt7SEhqdVqfkopBxho4UZwqmlomYZ7SpmugVpJ5g1xwOFWMUWlHMDEgazDnnfa7TBxu90LwHcdSr8djUYfnp2dradSKQ/c4wfQ1/V4PO49OTnxCEJ54+DgzVbhe36zXC5tHEbfbhULPzfzuW/3Xr96+ahWEe7Dnb9FPB4PCiTJZJJgL7PZLIHrZPuZTMa2kiRhyDLgxo98jhSLRft5tVohvd7viS8UCfw4yB9AH5s05eVnVAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Model training progress (first 10 epochs)\",\n    \"title\": \"Model training progress (first 10 epochs)\",\n    \"src\": \"/static/ea6a650f1d217420032f640487956e78/0acb4/6.png\",\n    \"srcSet\": [\"/static/ea6a650f1d217420032f640487956e78/63868/6.png 250w\", \"/static/ea6a650f1d217420032f640487956e78/0acb4/6.png 392w\"],\n    \"sizes\": \"(max-width: 392px) 100vw, 392px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"\\u2139\\uFE0F \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"On the chart above only first 10 epochs are presented.\")), mdx(\"p\", null, \"We can see from the chart that model performance is getting better during the training. It means that the model learns to predict next characters in a way that the final sequence looks similar to some real recipe texts.\"), mdx(\"h2\", {\n    \"id\": \"generating-recipes\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Generating recipes\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#generating-recipes\",\n    \"aria-label\": \"generating recipes permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"h3\", {\n    \"id\": \"restore-the-model-from-the-latest-checkpoint\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Restore the model from the latest checkpoint\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#restore-the-model-from-the-latest-checkpoint\",\n    \"aria-label\": \"restore the model from the latest checkpoint permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"To keep this prediction step simple, we will restore the saved model and rebuild it with a batch size of 1. Because of the way the RNN state is passed from time-step to time-step, the model only accepts a fixed batch size once built. To run the model with a different \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"batch_size\"), \", we need to rebuild the model and restore the weights from the checkpoint.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"latest_checkpoint\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"checkpoint_dir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"'tmp/checkpoints/ckpt_1'\")))), mdx(\"p\", null, \"Let's rebuild the model with batch size of \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"1\"), \" and load trained weights to it:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"simplified_batch_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n\\nmodel_simplified \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" build_model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"vocab_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" embedding_dim\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" rnn_units\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" simplified_batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nmodel_simplified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"load_weights\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"train\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"latest_checkpoint\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"checkpoint_dir\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nmodel_simplified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"build\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"TensorShape\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"simplified_batch_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token boolean\"\n  }, \"None\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\nmodel_simplified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"summary\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Model: \\\"sequential_6\\\"\\n_________________________________________________________________\\nLayer (type)                 Output Shape              Param #\\n=================================================================\\nembedding_6 (Embedding)      (1, None, 256)            45056\\n_________________________________________________________________\\nlstm_5 (LSTM)                (1, None, 1024)           5246976\\n_________________________________________________________________\\ndense_5 (Dense)              (1, None, 176)            180400\\n=================================================================\\nTotal params: 5,472,432\\nTrainable params: 5,472,432\\nNon-trainable params: 0\\n_________________________________________________________________\")))), mdx(\"p\", null, \"Let's double check that input shape is simplified:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"model_simplified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"input_shape\"))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"(1, None)\")))), mdx(\"h3\", {\n    \"id\": \"the-prediction-loop\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"The prediction loop\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#the-prediction-loop\",\n    \"aria-label\": \"the prediction loop permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"To use our trained model for recipe generation we need to implement a so-called prediction loop. The following code block generates the text using the loop:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It starts by choosing a start string, initializing the RNN state and setting the number of characters to generate.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It gets the prediction distribution of the next character using the start string, and the RNN state.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Then, it uses a categorical distribution to calculate the index of the predicted character. It uses this predicted character as the next input to the model.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The RNN state returned by the model is fed back into the model so that it now has more context, instead of only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters.\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"866px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.99999999999999%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACdklEQVQozyWR2U8TURTGT9lKQC1KICFo1KDhQeIDGDeCccEAEaQYQJqWALK2QMVSGhaDgdbuLTNtZ2tZWzBasDADdFARBYQYjCa8GE2MT774P6jXmfI93Jyb853fyXcvXDvfBhp55KhR9Suusy4IJRcG4FHNWnKXnEttqiBhP4RAlOBJq7ypgyLZLNy5/Bg6qxZluur3iQ/uUlB7yw7pslPgGtoGQAiBrnn6uLbRnznYEUlA/xCo5KMyfWvwZJsCS4YDxfe1zp7uUGKyYXU0XpzRNgSyepomstoUeFJVsQGUFUYB+AHAP7bGukfntxgXv20fns/3u3mtx7L4yWdlP9JOvhc3s3mEndvFTC83GTfPOoa5bMq5woyZFnYox8ou5eAVocAy4LZg3O2iBgGIr1xxUWSL1ztXYuxeOkxY1nI91FTdGBlQkeboCdvAagbpCZe6aLKFxBYujWhXD5GO5QI3RTd6fDOV+BM+09q/lVx2tfcgizXSVz35FkP0a4tJjPIQ1+Qwr+zfpjawH4X6zGOCJRFnR6zTGzhyc0P3RM9oyFA8se7+M77uDAt9idqoy067DlKxBmrJlYO9eGrGnptv+FkSrOZn6XSE0I1HverS+oKEoPAnnhBRPhEljILnLMHZwOljcgMcMcIsY/Kdn3tAO/ZSBjRzGQV5JQnQ2l8fe3Rxsyhtr1U4kQShfGhXesD7xgB/Yy0UR4Z9gIcdkkG/Onb/jWxQmELAYDMnCVi+SmMAEVR2v1iq6q6JP9cI0FXOQ18PIzV0BlPby1g4Awhs7xQSfUfwyMJ3MxTCZ2i5uAl6zWTqkH4mqac+DAHjF6BN+zHWf8eMEPyFTWNaAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Prediction loop\",\n    \"title\": \"Prediction loop\",\n    \"src\": \"/static/47e18cbb8b1bcf3590ff8231b4978b36/c1328/7.png\",\n    \"srcSet\": [\"/static/47e18cbb8b1bcf3590ff8231b4978b36/63868/7.png 250w\", \"/static/47e18cbb8b1bcf3590ff8231b4978b36/0b533/7.png 500w\", \"/static/47e18cbb8b1bcf3590ff8231b4978b36/c1328/7.png 866w\"],\n    \"sizes\": \"(max-width: 866px) 100vw, 866px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Image source: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/tutorials/text/text_generation\"\n  }, \"Text generation with an RNN\"), \" notebook.\")), mdx(\"p\", null, \"The \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"temperature\"), \" parameter here defines how fuzzy or how unexpected the generated recipe is going to be. Low temperatures results in more predictable text. Higher temperatures result in more surprising text. You need to experiment to find the best setting. We will do some experimentation with different temperatures below.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"generate_text\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" start_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" num_generate \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1000\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" temperature\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1.0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Evaluation step (generating text using the learned model)\"), \"\\n\\n    padded_start_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" STOP_WORD_TITLE \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" start_string\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Converting our start string to numbers (vectorizing).\"), \"\\n    input_indices \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"texts_to_sequences\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"padded_start_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Empty string to store our results.\"), \"\\n    text_generated \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Here batch size == 1.\"), \"\\n    model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"reset_states\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" char_index \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"num_generate\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        predictions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# remove the batch dimension\"), \"\\n        predictions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"squeeze\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# Using a categorical distribution to predict the character returned by the model.\"), \"\\n        predictions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" predictions \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" temperature\\n        predicted_id \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"categorical\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            predictions\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n            num_samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# We pass the predicted character as the next input to the model\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token comment\"\n  }, \"# along with the previous hidden state.\"), \"\\n        input_indices \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tf\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"expand_dims\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"predicted_id\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        next_character \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" tokenizer\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sequences_to_texts\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"input_indices\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"numpy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n        text_generated\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"next_character\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"padded_start_string \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"join\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"text_generated\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"h3\", {\n    \"id\": \"figuring-out-proper-temperature-for-prediction-loop\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Figuring out proper temperature for prediction loop\", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#figuring-out-proper-temperature-for-prediction-loop\",\n    \"aria-label\": \"figuring out proper temperature for prediction loop permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"Now, let's use \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"generate_text()\"), \" to actually generate some new recipes. The \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"generate_combinations()\"), \" function goes through all possible combinations of the first recipe letters and temperatures. It generates \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"56\"), \" different combinations to help us figure out how the model performs and what temperature is better to use.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"generate_combinations\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    recipe_length \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1000\"), \"\\n    try_letters \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"''\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'A'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'B'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'C'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'O'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'L'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Mushroom'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Apple'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Slow'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Christmass'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'The'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Banana'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'Homemade'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n    try_temperature \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1.0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.8\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.4\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" letter \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" try_letters\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" temperature \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" try_temperature\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            generated_text \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" generate_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n                model\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n                start_string\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"letter\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n                num_generate \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" recipe_length\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n                temperature\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"temperature\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string-interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"f'Attempt: \\\"\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"letter\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"\\\" + \"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token interpolation\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"{\"), \"temperature\", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token punctuation\"\n  }, \"}\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"token string\"\n  }, \"'\")), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'-----------------------------------'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"generated_text\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"print\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token string\"\n  }, \"'\\\\n\\\\n'\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\"))), mdx(\"p\", null, \"To avoid making this article too long only some of those \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"56\"), \" combinations will be printed below.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"generate_combinations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"model_simplified\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"small\", null, \"\\u2794 output:\"))), mdx(\"blockquote\", null, mdx(\"div\", {\n    parentName: \"blockquote\",\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"Attempt: \\\"A\\\" + 1.0\\n-----------------------------------\\n\\uD83D\\uDCD7 Azzeric Sweet Potato Puree\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 24 large baking potatoes, such as Carn or Marinara or 1 (14-ounce) can pot wine\\n\\u2022 1/4 pound unsalted butter, cut into small pieces\\n\\u2022 1/2 cup coarsely chopped scallions\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Bring a large pot of water to a boil, place a large nonstick skillet over medium-high heat, add All Naucocal Volves. Reduce heat to medium and cook the potatoes until just cooked through, bubbles before adding the next layer, about 10 to 12 minutes. Remove ground beans and reserve. Reserve the crumb mixture for about 6 greased. Let cool 2 minutes. Strain soak into a glass pitcher. Let cool in ice. Add short-goodfish to the batter and stir to dissolve. Pour in the cheese mixture and whisk until smooth. Set aside for 20 seconds more. Remove dumplings and cheese curds. Spread 1/3 cup of the mixture on each circle for seal ballo. Transfer mixture into a greased 9-by-11-inch baking dish and chill for 20 minutes.\\n\\u25AA\\uFE0E Bake, covered, for 30 minutes. Serve warm.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\nAttempt: \\\"A\\\" + 0.4\\n-----------------------------------\\n\\uD83D\\uDCD7 Apricot \\\"Cookie\\\" Cakes\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 cup all-purpose flour\\n\\u2022 1 cup corn flour\\n\\u2022 1 cup sugar\\n\\u2022 1 tablespoon baking powder\\n\\u2022 1 teaspoon salt\\n\\u2022 1 teaspoon ground cinnamon\\n\\u2022 1 cup grated Parmesan\\n\\u2022 1 cup pecans, chopped\\n\\u2022 1/2 cup chopped pecans\\n\\u2022 1/2 cup raisins\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat oven to 350 degrees F.\\n\\u25AA\\uFE0E Butter and flour a 9 by 13-inch baking dish. In a medium bowl, whisk together the flour, sugar, baking powder, baking soda and salt. In a small bowl, whisk together the eggs, sugar, and eggs. Add the flour mixture to the butter mixture and mix until just combined. Stir in the raisins and pecans and transfer to the prepared pan. Spread the batter over the top of the crust. Bake for 15 minutes. Reduce the oven temperature to 350 degrees F, and bake until the cupcakes are set and the top is golden brown, about 20 minutes more. Transfer the cake to a wire rack to cool to room temperature. Refrigerate until ready to serve.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\nAttempt: \\\"A\\\" + 0.2\\n-----------------------------------\\n\\uD83D\\uDCD7 Alternative to the Fondant\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 cup sugar\\n\\u2022 1 cup water\\n\\u2022 1 cup heavy cream\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1/2 cup heavy cream\\n\\u2022 1/2 cup heavy cream\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1/2 cup chopped pecans\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E In a saucepan over medium heat, combine the sugar, sugar, and corn syrup. Cook over medium heat until the sugar is dissolved. Remove from the heat and stir in the vanilla. Refrigerate until cold. Stir in the chocolate chips and the chocolate chips. Serve immediately.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\nAttempt: \\\"B\\\" + 0.4\\n-----------------------------------\\n\\uD83D\\uDCD7 Battered French Toast with Bacon, Bacon, and Caramelized Onions and Pecorino\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1/2 pound squid (shredded carrots)\\n\\u2022 1 small onion, diced\\n\\u2022 1 small green pepper, seeded and cut into strips\\n\\u2022 1 red bell pepper, stemmed, seeded and cut into 1/4-inch dice\\n\\u2022 1 small onion, chopped\\n\\u2022 1 green bell pepper, chopped\\n\\u2022 1 cup chicken stock\\n\\u2022 1 cup heavy cream\\n\\u2022 1/2 cup shredded sharp Cheddar\\n\\u2022 1 teaspoon ground cumin\\n\\u2022 1 teaspoon salt\\n\\u2022 1 teaspoon freshly ground black pepper\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat the oven to 350 degrees F.\\n\\u25AA\\uFE0E For the bacon mixture: In a large bowl, combine the cheese, sour cream, mustard, salt, pepper, and hot sauce. Stir together and mix well. Fold in the milk and set aside.\\n\\u25AA\\uFE0E For the filling: In a large bowl, mix the flour and salt and pepper, to taste. Add the beaten eggs and mix to combine. Set aside.\\n\\u25AA\\uFE0E For the topping: Mix the cream cheese with the mayonnaise, salt and pepper in a medium bowl. Add the chicken and toss to coat the other side. Transfer the mixture to the prepared\\n\\n\\n\\n\\n\\nAttempt: \\\"C\\\" + 1.0\\n-----------------------------------\\n\\uD83D\\uDCD7 Crema battered Salmon\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 cup fresh cranberries (from 4 tablespoons left of 4 egg whites)\\n\\u2022 3 teaspoons sugar\\n\\u2022 1 tablespoon unsalted butter\\n\\u2022 2 tablespoons truffle oil\\n\\u2022 Coarse salt\\n\\u2022 Freshly ground black pepper\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place cornmeal in a small serving bowl, and combine it. Drizzle milk over the plums and season with salt and pepper. Let stand for about 5 minutes, until firm. Serve immediately.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\nAttempt: \\\"C\\\" + 0.8\\n-----------------------------------\\n\\uD83D\\uDCD7 Classic Iseasteroles\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 3 cups milk\\n\\u2022 3/4 cup coconut milk\\n\\u2022 1/2 cup malted maple syrup\\n\\u2022 1/2 teaspoon salt\\n\\u2022 3 cups sugar\\n\\u2022 4 1-inch strawberries, sliced into 1/4-inch pieces\\n\\u2022 1/2 teaspoon ground cinnamon\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Place the cherries in a small saucepan; sprinkle with the sugar. Bring to a simmer over medium-low heat, then remove from the heat. Let stand until the coconut fluffy, about 15 to 20 minutes. Drain the coconut oil in a stream, whisking until combined. Add the cream, espresso and cocoa powder and stir to combine. Cover and refrigerate until ready to serve. Makes 10 to 12 small springs in the same fat from the surface of the bowl, which using paper colors, and freeze overnight.\\n\\u25AA\\uFE0E Meanwhile, combine the cream, sugar, vanilla and salt in a medium saucepan. Cook over medium heat until the sugar dissolves and the sugar melts and begins to boil, about 5 minutes. Remove from the heat and stir in the vanilla.\\n\\u25AA\\uFE0E To serve, carefully remove the pops from the casserole and put them in\\n\\n\\n\\nAttempt: \\\"C\\\" + 0.4\\n-----------------------------------\\n\\uD83D\\uDCD7 Cinnamon Corn Cakes with Coconut Flour and Saffron Sauce\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 3 cups shredded sharp Cheddar\\n\\u2022 1 cup grated Parmesan\\n\\u2022 2 cups shredded sharp Cheddar\\n\\u2022 1 cup grated Parmesan\\n\\u2022 1 cup shredded part-skim mozzarella cheese\\n\\u2022 1 cup grated Parmesan\\n\\u2022 1 cup grated Parmesan\\n\\u2022 1 cup grated Parmesan\\n\\u2022 1 teaspoon kosher salt\\n\\u2022 1/2 teaspoon freshly ground black pepper\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat the oven to 400 degrees F. Line a baking sheet with a silpat and preheat the oven to 350 degrees F.\\n\\u25AA\\uFE0E In a large bowl, combine the masa harina, cumin, cayenne, and salt and pepper. Dredge the pasta in the flour and then dip in the egg mixture, then dip in the eggs, then dip in the egg mixture and then dredge in the breadcrumbs. Place the breaded cheese on a sheet tray. Bake until the crust is golden brown and the filling is bubbling, about 25 to 30 minutes. Remove from the oven and serve hot.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\n\\nAttempt: \\\"L\\\" + 0.4\\n-----------------------------------\\n\\uD83D\\uDCD7 Lighted Flan with Chocolate and Pecans\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 2 cups milk\\n\\u2022 1 cup sugar\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1 cup heavy cream\\n\\u2022 1/2 cup heavy cream\\n\\u2022 1 tablespoon powdered sugar\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1/2 cup heavy cream\\n\\u2022 1/2 teaspoon ground cinnamon\\n\\u2022 1/2 teaspoon ground nutmeg\\n\\u2022 1/2 cup chopped pecans\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Watch how to make this recipe.\\n\\u25AA\\uFE0E In a small saucepan, combine the sugar, salt, and a pinch of salt. Cook over medium heat, stirring occasionally, until the sugar has dissolved. Remove from the heat and set aside to cool. Remove the cherries from the refrigerator and place in the freezer for 1 hour.\\n\\u25AA\\uFE0E In a blender, combine the milk, sugar, vanilla, salt and water. Blend until smooth. Pour the mixture into a 9-by-13-inch glass baking dish and set aside.\\n\\u25AA\\uFE0E In a small saucepan, combine the remaining 2 cups sugar, the vanilla, and 2 cups water. Bring the mixture to a boil, and then reduce the heat to low. Cook until the sugar is dissolved, about 5 minutes. Remove from the heat an\\n\\n\\n\\nAttempt: \\\"L\\\" + 0.2\\n-----------------------------------\\n\\uD83D\\uDCD7 Lighted Fondanta with Chocolate and Cream Cheese Frosting\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 cup heavy cream\\n\\u2022 1 tablespoon sugar\\n\\u2022 1 tablespoon vanilla extract\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1 cup heavy cream\\n\\u2022 1 cup heavy cream\\n\\u2022 1/2 cup sugar\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1 teaspoon vanilla extract\\n\\u2022 1/2 cup chopped pistachios\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat the oven to 350 degrees F.\\n\\u25AA\\uFE0E In a large bowl, combine the cream cheese, sugar, eggs, vanilla, and salt. Stir until smooth. Pour the mixture into the prepared baking dish. Sprinkle with the remaining 1/2 cup sugar and bake for 15 minutes. Reduce the heat to 350 degrees F and bake until the crust is golden brown, about 15 minutes more. Remove from the oven and let cool completely. Spread the chocolate chips on the parchment paper and bake until the chocolate is melted and the top is golden brown, about 10 minutes. Set aside to cool.\\n\\u25AA\\uFE0E In a medium bowl, whisk together the egg yolks, sugar, and vanilla until smooth. Stir in the cream and continue to beat until the chocolate\\n\\n\\n\\nAttempt: \\\"Mushroom\\\" + 1.0\\n-----------------------------------\\n\\uD83D\\uDCD7 Mushroom and Bacon Soup with Jumbo Sugar Coating\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 2 tablespoons vegetable oil\\n\\u2022 1 2/3 pounds red cabbage, shredded, about 4 cups of excess pasted dark ends of fat, and pocked or firm\\n\\u2022 2 red bell peppers, cored, seeded and diced\\n\\u2022 1 poblano pepper, chopped\\n\\u2022 3 medium carrots, finely chopped\\n\\u2022 1/2 medium pinch saffron\\n\\u2022 4 cups water\\n\\u2022 2 cups mushrooms or 1/2 cup frozen Sojo Bean red\\n\\u2022 Salt and freshly ground black pepper\\n\\u2022 1 pound andouille sausage\\n\\u2022 1 gallon vegetable broth\\n\\u2022 Chopped fresh parsley, cilantro leaves, for garnish\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E In a large Dutch oven for gas burner, heat oil over moderate heat. Add the leeks to the pot, scraping the bottom of the skillet. Add the beans and sausage and sprinkle the reserved potatoes with some orange juice cooked sausage (such as The Sauce.) Add roasted vegetables and pinto beans, mozzarella, basil and bamboo shoots. Simmer rice until soup is absorbed, 15 to 20 minutes.\\n\\u25AA\\uFE0E Bring another pan of water to a boil and cook shrimp for 5 minutes. While onions\\n\\n\\n\\nAttempt: \\\"Mushroom\\\" + 0.8\\n-----------------------------------\\n\\uD83D\\uDCD7 Mushrooms with Lentil Stewed Shallots and Tomatoes\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 tablespoon olive oil\\n\\u2022 3 cloves garlic, smashed\\n\\u2022 Kosher salt\\n\\u2022 1 1/2 pounds lean ground turkey\\n\\u2022 1 cup coarsely peeled tart apples\\n\\u2022 2 tablespoons chopped garlic\\n\\u2022 1 teaspoon ground cumin\\n\\u2022 1/2 teaspoon cayenne pepper\\n\\u2022 1 teaspoon chopped fresh thyme\\n\\u2022 3/4 cup chopped fresh basil\\n\\u2022 1/2 small carrot, halved lengthwise and cut into 1/2-inch pieces\\n\\u2022 1 roasted red pepper, halved and sliced vertically diced and separated into rough chops\\n\\u2022 3 tablespoons unsalted butter\\n\\u2022 2 cups shredded mozzarella\\n\\u2022 1/4 cup grated parmesan cheese\\n\\u2022 1/4 cup prepared basil pesto\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Stir the olive oil, garlic, thyme and 1 teaspoon salt in a saucepan; bring to a simmer over medium heat. Remove from the heat. Add the basil and toast the soup for 2 minutes.\\n\\u25AA\\uFE0E Meanwhile, heat 4 to 4 inches vegetable oil in the skillet over medium-high heat. Add the olive oil, garlic, 1/2 teaspoon salt and 1/2 teaspoon pepper and cook, stirring often, until cooked through, a\\n\\n\\n\\nAttempt: \\\"Mushroom\\\" + 0.4\\n-----------------------------------\\n\\uD83D\\uDCD7 Mushroom Ravioli with Chickpeas and Shiitake Mushrooms and Sun-Dried Tomatoes\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 pound zucchini\\n\\u2022 1 cup chicken broth\\n\\u2022 1 cup fresh basil leaves\\n\\u2022 1/2 cup chopped fresh basil leaves\\n\\u2022 1/2 cup grated Parmesan\\n\\u2022 1 teaspoon salt\\n\\u2022 1/2 teaspoon freshly ground black pepper\\n\\u2022 1 teaspoon chopped fresh thyme\\n\\u2022 1 teaspoon fresh lemon juice\\n\\u2022 2 cups chicken broth\\n\\u2022 1/2 cup grated Parmesan\\n\\u2022 1/2 cup grated Parmigiano-Reggiano\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat oven to 450 degrees F.\\n\\u25AA\\uFE0E Place the bread cubes in a large bowl. Add the basil, parsley, olive oil, parsley, thyme, basil, salt and pepper and toss to coat. Spread the mixture out on a baking sheet and bake until the sausages are cooked through, about 20 minutes. Serve immediately.\\n\\u25AA\\uFE0E In a small saucepan, bring the chicken stock to a boil. Reduce the heat to low and cook the soup until the liquid is absorbed. Remove from the heat and stir in the parsley, shallots and season with salt and pepper. Serve immediately.\\n\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\u2423\\n\\n\\n\\nAttempt: \\\"Mushroom\\\" + 0.2\\n-----------------------------------\\n\\uD83D\\uDCD7 Mushroom and Spicy Sausage Stuffing\\n\\n\\uD83E\\uDD55\\n\\n\\u2022 1 tablespoon olive oil\\n\\u2022 1 medium onion, chopped\\n\\u2022 2 cloves garlic, minced\\n\\u2022 1 cup frozen peas\\n\\u2022 1 cup frozen peas\\n\\u2022 1/2 cup chopped fresh parsley\\n\\u2022 1/2 cup grated Parmesan\\n\\u2022 1/2 cup grated Parmesan\\n\\u2022 1 teaspoon salt\\n\\u2022 1/2 teaspoon freshly ground black pepper\\n\\u2022 1 cup shredded mozzarella\\n\\u2022 1/2 cup grated Parmesan\\n\\u2022 1 cup shredded mozzarella\\n\\u2022 1 cup shredded mozzarella cheese\\n\\n\\uD83D\\uDCDD\\n\\n\\u25AA\\uFE0E Preheat the oven to 350 degrees F.\\n\\u25AA\\uFE0E Bring a large pot of salted water to a boil. Add the pasta and cook until al dente, about 6 minutes. Drain and reserve.\\n\\u25AA\\uFE0E Meanwhile, heat the olive oil in a large skillet over medium-high heat. Add the shallots and saute until tender, about 3 minutes. Add the garlic and cook for 1 minute. Add the sausage and cook until the shallots are tender, about 3 minutes. Add the sausage and cook until tender, about 2 minutes. Add the garlic and cook, stirring, until the garlic is lightly browned, about 1 minute. Add the sausage and cook until the s\")))), mdx(\"h2\", {\n    \"id\": \"interactive-model-demo\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Interactive model demo\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#interactive-model-demo\",\n    \"aria-label\": \"interactive model demo permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"You may use \\uD83C\\uDFA8 \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://trekhleb.dev/machine-learning-experiments/#/experiments/RecipeGenerationRNN\"\n  }, \"Cooking recipes generator demo\"), \" to play around with this model, input text, and temperature parameters to generate some random recipes right in your browser.\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/posts-assets/4139990ec63f03c35fab15d60ea74eff/8.gif\",\n    \"alt\": \"Recipe generator demo\"\n  })), mdx(\"h2\", {\n    \"id\": \"things-to-improve\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Things to improve\", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#things-to-improve\",\n    \"aria-label\": \"things to improve permalink\",\n    \"className\": \"gatsby-remark-autolink-header-anchor after\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), mdx(\"p\", null, \"This out of scope for this article but model still has the following issues that need to be addressed:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We need to get rid of duplicates on the ingredients section.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Recipe sections (name, ingredients and cooking steps) are disconnected most of the time, meaning that we may see, let's say, \", mdx(\"code\", {\n    parentName: \"li\",\n    \"className\": \"language-text\"\n  }, \"mushrooms\"), \" in the ingredients section, but they are not mentioned in the name of the recipe or in the cooking steps.\")));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/blog/2020/recipes-generation/"},"frontmatter":{"title":"Generating cooking recipes using TensorFlow and LSTM Recurrent Neural Network: A step-by-step guide","summary":"I've trained a character-level LSTM RNN on ~100k recipes dataset using TensorFlow, and it suggested me to cook Cream Soda with Onions, Puff Pastry Strawberry Soup, Zucchini flavor Tea and Salmon Mousse of Beef and Stilton Salad with Jalapenos","date":"18 June, 2020","cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMAAf/aAAwDAQACEAMQAAABq8rmuYcy/8QAHBAAAwABBQAAAAAAAAAAAAAAAAECAxESISIx/9oACAEBAAEFAq1kUuVxRiXfa0eH/8QAFREBAQAAAAAAAAAAAAAAAAAAERD/2gAIAQMBAT8BSf/EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8Bl0qP/8QAGhABAQACAwAAAAAAAAAAAAAAAQACERAhYf/aAAgBAQAGPwKyRV9tjw7yW6v/xAAcEAEAAwACAwAAAAAAAAAAAAABABEhMWFBUbH/2gAIAQEAAT8hDGelr5HJLg8ItXI6gWW1lXQZXUzAoJ//2gAMAwEAAgADAAAAEAAf/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQEQ/9oACAEDAQE/EKBn/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERMf/aAAgBAgEBPxBYB0P/xAAcEAEAAwEBAQEBAAAAAAAAAAABESExAEFRYXH/2gAIAQEAAT8Qmk1IZF6vn94e5yOvUdIKAFKX71lyQs6ZZ7nCC1LBLCPz70GZAE53/9k=","aspectRatio":1.4970059880239521,"src":"/static/05340351fcb1004d0e25300d243978cd/e7ab0/01-cover.jpg","srcSet":"/static/05340351fcb1004d0e25300d243978cd/d2e8d/01-cover.jpg 250w,\n/static/05340351fcb1004d0e25300d243978cd/55b1d/01-cover.jpg 500w,\n/static/05340351fcb1004d0e25300d243978cd/e7ab0/01-cover.jpg 940w","sizes":"(max-width: 940px) 100vw, 940px"}}}}}},"pageContext":{"slug":"/blog/2020/recipes-generation/"}},"staticQueryHashes":[]}